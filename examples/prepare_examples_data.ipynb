{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GNNLens Demo\n",
    "\n",
    "### Introduction\n",
    "This code is aiming to reproduce the data used in the demo: https://gnnlens.github.io/\n",
    "\n",
    "The data will be generated in the folder \"examples/examples_data\".\n",
    "\n",
    "After generating the data, you can use the command line to start the backend and frontend and check them in the browser.\n",
    "\n",
    "### Steps\n",
    "\n",
    "1. Prepare environments for running this notebook.\n",
    "\n",
    "`cd examples`\n",
    "\n",
    "`conda env create -f environment.yml`\n",
    "\n",
    "`cd ..`\n",
    "\n",
    "`conda activate gnnlens`\n",
    "\n",
    "`conda install dgl-cuda10.1==0.7.1 -c dglteam`\n",
    "\n",
    "`cd server`\n",
    "\n",
    "`pip install -r requirements.txt`\n",
    "\n",
    "`python setup.py install`\n",
    "\n",
    "`cd ..`\n",
    "\n",
    "2. Unzip the rawdata.zip in \"examples/rawdata\" folder.\n",
    "\n",
    "`cd examples`\n",
    "\n",
    "`unzip rawdata.zip`\n",
    "\n",
    "3. Run the whole jupyter notebook \"examples/prepare_examples_data.ipynb\" to generate data in the folder \"examples/examples_data\".\n",
    "\n",
    "4. Start the GNNLens backend. A complied version of frontend is located in \"server/gnnlens/visbuild\".\n",
    "\n",
    "`cd examples`\n",
    "\n",
    "`gnnlens --port 6800 --logdir examples_data`\n",
    "\n",
    "5. Check the GNNLens at browser.\n",
    "\n",
    "http://localhost:6800\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnnlens.GNNLensWriter as GNNLensWriter\n",
    "import time\n",
    "from utils import load_json, load_cora_ml_data, convert_data_package_to_dgl_graph, infer_pipeline, \\\n",
    "                    calculate_subgraph, initialize_cora_ml_explainer, GNNExplainer_explain, \\\n",
    "                    infer_pipeline_2, calculate_subgraph_2, initialize_photo_explainer, load_photo_data, GetModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Dump Folder Name\n",
    "dump_folder_name = \"examples_data\"\n",
    "\n",
    "### Raw Data Config\n",
    "root_path = \"./rawdata\"\n",
    "data_path = root_path+'/data/'\n",
    "model_config_path = root_path + \"/models/model_config.json\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer = GNNLensWriter(dump_folder_name)\n",
    "models_list = load_json(model_config_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cora_ML data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Graph into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Long time required.\n",
    "basic_config = models_list[\"25\"][\"graph_config\"]\n",
    "data_package, graph, labels, num_classes, features, idx_train, graph_additional_info = load_cora_ml_data(data_path, basic_config)\n",
    "dgl_graph = convert_data_package_to_dgl_graph(data_package)\n",
    "writer.add_graph(\"Cora_ML\", dgl_graph, labels, num_classes, features, calculate_metrics=True, additional_info=graph_additional_info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Model Inference Results into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_classes_GAT, output_vector_GAT = infer_pipeline(models_list, \"25\", root_path, data_path, \"cora_ml\")\n",
    "predicted_classes_GATWUF, output_vector_GATWUF = infer_pipeline(models_list, \"26\", root_path, data_path, \"cora_ml\")\n",
    "predicted_classes_MLP, output_vector_MLP = infer_pipeline(models_list, \"27\", root_path, data_path, \"cora_ml\")\n",
    "## Order: GAT --> MLP --> GATWUF\n",
    "#\"id\":26, \"name\": \"Cora_ML_GAT_Identity_Features\", --> GATWUF\n",
    "#\"id\":27  \"name\": \"Cora_ML_GAT_Identity_Structure\",  --> MLP\n",
    "writer.add_model(\"Cora_ML\", \"GAT\", predicted_classes_GAT, output_vector_GAT)\n",
    "writer.add_model(\"Cora_ML\", \"MLP\", predicted_classes_MLP, output_vector_MLP)\n",
    "writer.add_model(\"Cora_ML\", \"GATWUF\", predicted_classes_GATWUF, output_vector_GATWUF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Explanation Results by Integrated Gradient into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Long time required.\n",
    "net = GetModel(root_path, models_list, \"25\")['net']\n",
    "## For Cora_ML, calculating two nodes 0, and 2010\n",
    "## For Photo, calculating two nodes 0, and 115\n",
    "calculate_subgraph(writer, net, data_package, 0, predicted_classes_GAT, \"Cora_ML\", dgl_graph)\n",
    "calculate_subgraph(writer, net, data_package, 2010, predicted_classes_GAT, \"Cora_ML\", dgl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Explanation Results by GNNExplainer into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_args, explainer = initialize_cora_ml_explainer(net, data_package, labels, graph, features, idx_train)\n",
    "for explain_node_idx in [0, 2010]:\n",
    "    print(\"Explain {}\".format(explain_node_idx))\n",
    "    start_time = time.time()\n",
    "    GNNExplainer_explain(dgl_graph, explainer, prog_args, explain_node_idx, writer, \"Cora_ML\", features, 75)\n",
    "    print(\"Time: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Photo data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Graph into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_config = models_list[\"20\"][\"graph_config\"]\n",
    "data_package_2, graph, labels, num_classes, features, L, graph_additional_info = load_photo_data(data_path, basic_config)\n",
    "dgl_graph = convert_data_package_to_dgl_graph(data_package_2)\n",
    "writer.add_graph(\"Photo\", dgl_graph, labels, num_classes, features, calculate_metrics=True, additional_info=graph_additional_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Model Inference Results into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Order: GCN --> MLP --> GCNWUF (20 - 21 - 22)\n",
    "predicted_classes_GCN, output_vector_GCN = infer_pipeline_2(models_list, \"20\", root_path, data_path, \"Photo\")\n",
    "predicted_classes_MLP, output_vector_MLP = infer_pipeline_2(models_list, \"21\", root_path, data_path, \"Photo\")\n",
    "predicted_classes_GCNWUF, output_vector_GCNWUF = infer_pipeline_2(models_list, \"22\",  root_path, data_path, \"Photo\")\n",
    "writer.add_model(\"Photo\", \"GCN\", predicted_classes_GCN, output_vector_GCN)\n",
    "writer.add_model(\"Photo\", \"MLP\", predicted_classes_MLP, output_vector_MLP)\n",
    "writer.add_model(\"Photo\", \"GCNWUF\", predicted_classes_GCNWUF, output_vector_GCNWUF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Explanation Results by Integrated Gradient into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = GetModel(root_path, models_list, \"20\")['net']\n",
    "net.eval()\n",
    "calculate_subgraph_2(writer, net, data_package_2, features, L, 0, predicted_classes_GCN, \"Photo\", dgl_graph)\n",
    "calculate_subgraph_2(writer, net, data_package_2, features, L, 115, predicted_classes_GCN, \"Photo\", dgl_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add Explanation Results by GNNExplainer into Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prog_args, explainer = initialize_photo_explainer(net, data_package_2, labels, graph, features, L, idx_train)\n",
    "for explain_node_idx in [0, 115]:\n",
    "    print(\"Explain {}\".format(explain_node_idx))\n",
    "    start_time = time.time()\n",
    "    GNNExplainer_explain(dgl_graph, explainer, prog_args, explain_node_idx, writer, \"Photo\", features, 99.99)\n",
    "    print(\"Time: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flush Writer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
