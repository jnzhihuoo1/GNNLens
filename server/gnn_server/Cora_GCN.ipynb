{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2651383876800537\n"
     ]
    }
   ],
   "source": [
    "from dataloader import load_citation, load_citation_v2, load_citation_v3\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataf = \"../data/\"\n",
    "norm_type = \"SymNorm_tildeA\"\n",
    "#norm_type = \"sym_normalized_A\"\n",
    "original_graph, L, features, labels, idx_train,idx_val, idx_test, data_package = load_citation_v3(dataf,\"Cora\",norm_type=norm_type,cuda=False, identity_features=False)\n",
    "name = \"Cora\"\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import load_new_data\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataf = \"../data/\"\n",
    "norm_type = \"SymNorm_tildeA\"\n",
    "#norm_type = \"sym_normalized_A\"\n",
    "original_graph, L, features, labels, idx_train,idx_val, idx_test, graph_info = load_new_data(dataf,\"polblogs\",norm_type=norm_type,cuda=False, identity_features=True)\n",
    "name = \"polblogs\"\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(features.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(graph_info)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "/github/GNNVis/server/data/g2g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Evaluate Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from models import tgGAT\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import accuracy, set_seed\n",
    "\n",
    "\n",
    "model_path = \"../models/gat_cora_state.pkt\"\n",
    "#model_path = \"../models/mlp_cora_state.pkt\"\n",
    "#torch.save(model.state_dict(), model_path)\n",
    "#args = [1433,16,7,0.5]\n",
    "#args = [3703,16,6,0.5]\n",
    "#args = [500, 16, 3, 0.5]\n",
    "#args = [1222, 16, 2, 0.5]\n",
    "args = [1433, 1433, 8, 7, 1]\n",
    "\n",
    "kwargs = {\n",
    "}\n",
    "model = tgGAT(*args,**kwargs)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "model.eval()\n",
    "output = model(data_package)\n",
    "#loss_test = F.nll_loss(output[data.train_mask],labels[idx_test])\n",
    "acc_all = accuracy(output,data_package.y)\n",
    "print(acc_all.item())\n",
    "#acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "#print(loss_test.item(), acc_test.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from models import GCN\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import accuracy, set_seed\n",
    "\n",
    "\n",
    "model_path = \"../models/gcn_photo_state.pkt\"\n",
    "#model_path = \"../models/mlp_cora_state.pkt\"\n",
    "#torch.save(model.state_dict(), model_path)\n",
    "#args = [1433,16,7,0.5]\n",
    "#args = [3703,16,6,0.5]\n",
    "#args = [500, 16, 3, 0.5]\n",
    "#args = [1222, 16, 2, 0.5]\n",
    "args = [745, 16, 8, 0.5]\n",
    "\n",
    "kwargs = {\n",
    "    \"bias\": True,\n",
    "}\n",
    "model = GCN(*args,**kwargs)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "model.eval()\n",
    "output = model(features,L)\n",
    "loss_test = F.nll_loss(output[idx_test],labels[idx_test])\n",
    "acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "print(loss_test.item(), acc_test.item())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Calculate Node Feature Importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = features.requires_grad_()\n",
    "output = model(features,L)\n",
    "N = 645\n",
    "node_relevance = torch.zeros_like(output)\n",
    "node_relevance[N] = 1\n",
    "output.backward(node_relevance)\n",
    "\n",
    "node_feature_importance = features.grad\n",
    "node_importance = features.grad.pow(2).sum(dim=1)\n",
    "node_importance = node_importance.tolist()\n",
    "\n",
    "#for i in range(len(node_importance)):\n",
    "#    if not node_importance[i] == 0:\n",
    "#        pass\n",
    "#        #print(i, node_importance[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_importance = features.grad[645]\n",
    "features_importance = features_importance.tolist()\n",
    "feature_index = sorted(range(len(features_importance)), key=lambda k: -features_importance[k])\n",
    "for index in feature_index:\n",
    "    print(index, features_importance[index])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_out = net(batch)[0]\n",
    "\n",
    "N = node_no\n",
    "node_relevance = torch.zeros_like(graph_out.node_features)\n",
    "node_relevance[N] = 1\n",
    "\n",
    "graph_in.zero_grad_()\n",
    "graph_out.node_features.backward(node_relevance)\n",
    "\n",
    "node_importance = batch.node_features.grad.pow(2).sum(dim=1)\n",
    "edge_importance = batch.edge_features.grad.pow(2).sum(dim=1)\n",
    "return node_importance, edge_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Visualize Weights in Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.state_dict()[\"gc1.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set()\n",
    "#uniform_data = np.random.rand(10, 12)\n",
    "ax = sns.heatmap(model.state_dict()[\"gc2.weight\"].cpu().numpy())\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"gc2_weight.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_graph._indices()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(original_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Visualize Graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "from fa2 import ForceAtlas2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "G = nx.Graph()\n",
    "indices = original_graph._indices().tolist()\n",
    "edge_num = len(indices[0])\n",
    "edge_index = [(indices[0][i], indices[1][i]) for i in range(edge_num)]\n",
    "node_index = list(range(features.shape[0]))\n",
    "G.add_nodes_from(node_index)\n",
    "G.add_edges_from(edge_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forceatlas2 = ForceAtlas2(\n",
    "                        # Behavior alternatives\n",
    "                        outboundAttractionDistribution=True,  # Dissuade hubs\n",
    "                        linLogMode=False,  # NOT IMPLEMENTED\n",
    "                        adjustSizes=False,  # Prevent overlap (NOT IMPLEMENTED)\n",
    "                        edgeWeightInfluence=1.0,\n",
    "\n",
    "                        # Performance\n",
    "                        jitterTolerance=1.0,  # Tolerance\n",
    "                        barnesHutOptimize=True,\n",
    "                        barnesHutTheta=1.2,\n",
    "                        multiThreaded=False,  # NOT IMPLEMENTED\n",
    "\n",
    "                        # Tuning\n",
    "                        scalingRatio=2.0,\n",
    "                        strongGravityMode=False,\n",
    "                        gravity=1.0,\n",
    "\n",
    "                        # Log\n",
    "                        verbose=True)\n",
    "\n",
    "positions = forceatlas2.forceatlas2_networkx_layout(G, pos=None, iterations=500)\n",
    "nx.draw_networkx_nodes(G, positions, node_size=20, with_labels=False, node_color=\"blue\", alpha=0.4)\n",
    "nx.draw_networkx_edges(G, positions, edge_color=\"green\", alpha=0.05)\n",
    "plt.axis('off')\n",
    "plt.show()\n",
    "\n",
    "# equivalently\n",
    "#import igraph\n",
    "#G = igraph.Graph.TupleList(G.edges(), directed=False)\n",
    "#layout = forceatlas2.forceatlas2_igraph_layout(G, pos=None, iterations=2000)\n",
    "#igraph.plot(G, layout).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newlist = list(positions.keys())\n",
    "newlist.sort()\n",
    "newPos = []\n",
    "for i in range(len(newlist)):\n",
    "    newPos.append([positions[i][0], positions[i][1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(newlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"../data/{}/{}_layout.pkt\".format(name,name),\"wb\") as f:\n",
    "    pkl.dump(newPos, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle as pkl\n",
    "with open(\"../data/{}/{}_layout.pkt\".format(name,name),\"rb\") as f:\n",
    "    newPos = pkl.load(f)\n",
    "    print(newPos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. GCN hook definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import skcuda.linalg as sklin\n",
    "from layer import GCN_layer\n",
    "from utils import accuracy\n",
    "'''\n",
    "GCN_layer(ind,outd,bias=True)\n",
    "'''\n",
    "\n",
    "class GCN_hook(nn.Module):\n",
    "    def __init__(self, num_feature,num_hidden,num_class,dropout,bias=True):\n",
    "        super(GCN_hook,self).__init__()\n",
    "\n",
    "        self.gc1 = GCN_layer(num_feature, num_hidden)\n",
    "        self.gc2 = GCN_layer(num_hidden, num_class)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x1 = F.dropout(x, self.dropout, training=self.training)\n",
    "        x2 = self.gc2(x1, adj)\n",
    "        return F.log_softmax(x2, dim=1), x1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name2 = \"photo\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"../models/gcn_{}_state.pkt\".format(name2)\n",
    "#torch.save(model.state_dict(), model_path)\n",
    "#args_input = [3703,16,6,0.5]\n",
    "#args_input = [500, 16, 3, 0.5]\n",
    "#args_input = [2879, 16, 7, 0.5]\n",
    "#args_input = [1222, 16, 2, 0.5]\n",
    "args_input = [745, 16, 8, 0.5]\n",
    "kwargs = {\n",
    "    \"bias\": True\n",
    "}\n",
    "model = GCN_hook(*args_input,**kwargs)\n",
    "model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "model.eval()\n",
    "output, inner_state = model(features,L)\n",
    "loss_test = F.nll_loss(output[idx_test],labels[idx_test])\n",
    "acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "print(loss_test.item(), acc_test.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. T-SNE Visualization for Input, Hidden, Output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import pickle as pkl\n",
    "\n",
    "def dimension_reduction(input_array):\n",
    "    start_time = time.time()\n",
    "    X = np.array(input_array)    \n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "    print(time.time() - start_time)\n",
    "    return X_embedded\n",
    "def visualize(embedded_array,labels):\n",
    "    \n",
    "    #sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "    X = np.array(embedded_array)\n",
    "    labels = np.array(labels)\n",
    "    labels = np.expand_dims(labels, axis=1)\n",
    "    data = np.concatenate((X, labels), axis=1)\n",
    "    df = pd.DataFrame(data, columns=[\"x\", \"y\",\"Labels\"])\n",
    "    # Create an array with the colors you want to use\n",
    "    colors = [\"#FF0B04\", \"#4374B3\"]\n",
    "    # Set your custom color palette\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "    ax = sns.scatterplot(x=\"x\", y=\"y\",hue=\"Labels\", data=df, palette=\"Set1\", legend=False)\n",
    "    \n",
    "current_palette = sns.color_palette()\n",
    "sns.palplot(current_palette)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input Layer\n",
    "features_array = features.cpu().detach().numpy()\n",
    "features_embeddded_array = dimension_reduction(features_array)\n",
    "visualize(features_embeddded_array, labels.cpu().detach().numpy())\n",
    "with open(\"../data/{}/{}_tsne_input.pkt\".format(name,name),\"wb\") as f:\n",
    "    pkl.dump(features_embeddded_array, f)\n",
    "    print(\"Done!\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Hidden Layer\n",
    "labels_array = labels.cpu().detach().numpy()\n",
    "layer2 = inner_state\n",
    "layer2_array = layer2.cpu().detach().numpy()\n",
    "layer2_embeddded_array = dimension_reduction(layer2_array)\n",
    "visualize(layer2_embeddded_array, labels.cpu().detach().numpy())\n",
    "with open(\"../data/{}/{}_tsne_hidden.pkt\".format(name,name),\"wb\") as f:\n",
    "    pkl.dump(layer2_embeddded_array, f)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output Layer\n",
    "input_array = output.cpu().detach().numpy()\n",
    "labels_array = labels.cpu().detach().numpy()\n",
    "embedded_array = dimension_reduction(input_array)\n",
    "visualize(embedded_array, labels.cpu().detach().numpy())\n",
    "with open(\"../data/{}/{}_tsne_output.pkt\".format(name,name),\"wb\") as f:\n",
    "    pkl.dump(embedded_array, f)\n",
    "    print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
