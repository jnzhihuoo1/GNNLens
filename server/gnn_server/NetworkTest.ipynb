{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data from URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import time\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cora_GCN\n",
    "url_list = [\"http://localhost:7777/api/graph_info?dataset_id=4&model_id=4&explain_id=4&graph_id=1\"]\n",
    "r = getUrl(url_list[0])\n",
    "receive_obj = json.loads(r.text)\n",
    "print(len(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"http://localhost:7777/api/rule_mining?dataset_id=4\"]\n",
    "r = getUrl(url_list[0])\n",
    "receive_obj = json.loads(r.text)\n",
    "print(len(r.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_id in [4,5,6,7,9,13]:\n",
    "    #dataset_id = dataset_id\n",
    "    start_time = time.time()\n",
    "    url_list = [\"http://localhost:7777/api/rule_mining?dataset_id={}\".format(dataset_id)]\n",
    "    r = getUrl(url_list[0])\n",
    "    print(dataset_id, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dataset_id in [4,5,6,7,9,13]:\n",
    "    #dataset_id = dataset_id\n",
    "    start_time = time.time()\n",
    "    url_list = [\"http://localhost:7777/api/graph_bundle_info?dataset_id={}\".format(dataset_id)]\n",
    "    r = getUrl(url_list[0])\n",
    "    print(dataset_id, time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Test Compress and Decompress."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import gzip\n",
    "\n",
    "def compress_data(data):\n",
    "    # Convert to JSON\n",
    "    json_data = json.dumps(data, indent=2)\n",
    "    # Convert to bytes\n",
    "    encoded = json_data.encode('utf-8')\n",
    "    # Compress\n",
    "    compressed = gzip.compress(encoded)\n",
    "    return compressed\n",
    "def decompress_data(compressed):\n",
    "    # Decompress\n",
    "    encoded = gzip.decompress(compressed)\n",
    "    # Convert to string\n",
    "    json_data = encoded.decode('utf-8')\n",
    "    # Convert to JSON\n",
    "    data = json.loads(json_data)\n",
    "    return data\n",
    "import time\n",
    "start_time = time.time()\n",
    "compressed = compress_data(receive_obj)\n",
    "data = decompress_data(compressed)\n",
    "print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Cache JSON."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 0.8634727001190186\n",
      "5 1.1725950241088867\n",
      "6 9.1912522315979\n",
      "7 1.549485206604004\n",
      "9 9.383479356765747\n",
      "13 1.6043713092803955\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "for dataset_id in [4,5,6,7,9,13]:\n",
    "    #dataset_id = dataset_id\n",
    "    start_time = time.time()\n",
    "    url_list = [\"http://localhost:7777/api/graph_bundle_info?dataset_id={}\".format(dataset_id)]\n",
    "    CACHE_DIR = \"../Cache/\"\n",
    "    VERSION = \"V1_2\"\n",
    "    r = getUrl(url_list[0])\n",
    "    receive_obj = json.loads(r.text)\n",
    "\n",
    "\n",
    "    with open(CACHE_DIR+\"cache_bundle_{}_{}.json\".format(dataset_id, VERSION), \"w\") as f:\n",
    "        json.dump(receive_obj, f)\n",
    "    end_time = time.time()\n",
    "    print(dataset_id, end_time - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['graph_obj', 'success'])\n"
     ]
    }
   ],
   "source": [
    "with open(CACHE_DIR+\"cache_bundle_{}_{}.json\".format(dataset_id, VERSION), \"r\") as f:\n",
    "    receive_obj = json.load(f)\n",
    "print(receive_obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_list = [\"http://localhost:7777/api/datasets\"]\n",
    "r = getUrl(url_list[0])\n",
    "receive_obj = json.loads(r.text)\n",
    "with open(CACHE_DIR+\"datasetlist_{}.json\".format(VERSION), \"w\") as f:\n",
    "    json.dump(receive_obj, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A different version of cacheing json."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "import gzip\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "dataset_id = 4\n",
    "url_list = [\"http://localhost:7777/api/graph_bundle_info?dataset_id={}\".format(dataset_id)]\n",
    "CACHE_DIR = \"../Cache/\"\n",
    "VERSION = \"V1_1\"\n",
    "r = getUrl(url_list[0])\n",
    "receive_obj = json.loads(r.text)\n",
    "# Convert to JSON\n",
    "json_data = json.dumps(receive_obj, indent=2)\n",
    "# Convert to bytes\n",
    "encoded = json_data.encode('utf-8')\n",
    "\n",
    "with gzip.open(CACHE_DIR+\"cache_bundle_{}_{}.json.gz\".format(dataset_id, VERSION), \"wb\") as f:\n",
    "    f.write(encoded)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with gzip.open(CACHE_DIR+\"cache_bundle_{}_{}.json.gz\".format(dataset_id, VERSION), \"rb\") as f:\n",
    "    data = f.read()\n",
    "# Convert to string\n",
    "json_data = data.decode('utf-8')\n",
    "# Convert to JSON\n",
    "receive_obj = json.loads(json_data)\n",
    "print(receive_obj.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(compressed[0:50])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Speed test of servers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "# Photo\n",
    "for dataset_id in [4,4,5,5,6,6,7,7,9,9]:\n",
    "    #for dataset_id in [4,4]:\n",
    "    start_time = time.time()\n",
    "    url_list = [\"http://localhost:7777/api/graph_bundle_info?dataset_id={}\".format(dataset_id)]\n",
    "    r = getUrl(url_list[0])\n",
    "    duration_time = time.time() - start_time\n",
    "    #print(duration_time)\n",
    "    #print(len(r.text))\n",
    "    receive_obj = json.loads(r.text)\n",
    "    #print(receive_obj.keys())\n",
    "    \n",
    "    if receive_obj[\"success\"] == True:\n",
    "        graph_obj = receive_obj[\"graph_obj\"]\n",
    "        #graph_obj = decompress_data(receive_obj[\"graph_obj\"])\n",
    "        print(graph_obj[\"common\"][\"name\"], duration_time)\n",
    "        #print(receive_obj[\"graph_obj\"].keys())\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Not success dataset_id:{} time:{}\".format(dataset_id, duration_time))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cora\n",
    "#No cache: 6s\n",
    "#Cache: 1s\n",
    "\n",
    "# Photo\n",
    "#No Cache: 24s\n",
    "#Cache: \n",
    "\n",
    "\n",
    "#citeseer 43.84026622772217  (No Cache, No Cache SPD, KFS)\n",
    "#citeseer 1.2933223247528076   (Cache)\n",
    "\n",
    "#pubmed 598.2629690170288\n",
    "#pubmed 6.6324803829193115\n",
    "\n",
    "#cora_ml 63.03324055671692\n",
    "#cora_ml 1.2183799743652344\n",
    "\n",
    "#polblogs 21.464422702789307\n",
    "#polblogs 0.7255387306213379"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Analyze Data Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "receive_obj = json.loads(r.text)\n",
    "if receive_obj[\"success\"] == True:\n",
    "    print(receive_obj[\"graph_obj\"].keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_obj = receive_obj[\"graph_obj\"]\n",
    "output_class = graph_obj[\"graph_out\"][\"node_features\"]\n",
    "ground_truth_class = graph_obj[\"graph_target\"][\"node_features\"]\n",
    "TF_class = []\n",
    "for i in range(len(output_class)):\n",
    "    TF_class.append(output_class[i]==ground_truth_class[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding = graph_obj[\"graph_out\"][\"output_vector\"]\n",
    "print(embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Construct confusion dict / matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_dict = {}\n",
    "for i in range(len(output_class)):\n",
    "    ground_truth = ground_truth_class[i]\n",
    "    output = output_class[i]\n",
    "    if not ground_truth in confusion_dict:\n",
    "        confusion_dict[ground_truth] = {}\n",
    "    if not output in confusion_dict[ground_truth]:\n",
    "        confusion_dict[ground_truth][output] = 0\n",
    "    confusion_dict[ground_truth][output] = confusion_dict[ground_truth][output] + 1\n",
    "print(confusion_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_confusion_matrix(confusion_dict, class_num):\n",
    "    confusion_matrix = []\n",
    "    for i in range(class_num):\n",
    "        # Ground Truth\n",
    "        this_class_confusion_dict = confusion_dict[i]\n",
    "        this_class_confusion_matrix = []\n",
    "        for j in range(class_num):\n",
    "            value = 0\n",
    "            if j in this_class_confusion_dict:\n",
    "                value = this_class_confusion_dict[j]\n",
    "            this_class_confusion_matrix.append(value)\n",
    "        confusion_matrix.append(this_class_confusion_matrix)\n",
    "    return confusion_matrix\n",
    "confusion_matrix = construct_confusion_matrix(confusion_dict, 7)\n",
    "print(confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np; np.random.seed(0)\n",
    "import seaborn as sns; sns.set()\n",
    "#uniform_data = np.random.rand(10, 12)\n",
    "ax = sns.heatmap(confusion_matrix,annot=True,fmt=\"d\",cmap=\"YlGnBu\",linewidths=.5)\n",
    "fig = ax.get_figure()\n",
    "fig.savefig(\"confusion_matrix.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Load Multiple Data Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "def getClass(graph_obj):\n",
    "    output_class = graph_obj[\"graph_out\"][\"node_features\"]\n",
    "    ground_truth_class = graph_obj[\"graph_target\"][\"node_features\"]\n",
    "    TF_class = []\n",
    "    for i in range(len(output_class)):\n",
    "        TF_class.append(output_class[i]==ground_truth_class[i])\n",
    "    return [ground_truth_class, output_class, TF_class]\n",
    "def getScoreOnGroundTruth(graph_obj):\n",
    "    output_vector = graph_obj[\"graph_out\"][\"output_vector\"]\n",
    "    ground_truth_class = graph_obj[\"graph_target\"][\"node_features\"]\n",
    "    score_list = []\n",
    "    for i in range(len(output_vector)):\n",
    "        ground_truth = ground_truth_class[i]\n",
    "        score = output_vector[i][ground_truth]\n",
    "        score_list.append(score)\n",
    "    return score_list\n",
    "def getScoreOnPrediction(graph_obj):\n",
    "    output_vector = graph_obj[\"graph_out\"][\"output_vector\"]\n",
    "    prediction_class = graph_obj[\"graph_out\"][\"node_features\"]\n",
    "    score_list = []\n",
    "    for i in range(len(output_vector)):\n",
    "        prediction_label = prediction_class[i]\n",
    "        score = output_vector[i][prediction_label]\n",
    "        score_list.append(score)\n",
    "    return score_list\n",
    "def overall_for_one_dataset(url):\n",
    "    r = getUrl(url)\n",
    "    return getClass(r)\n",
    "# Cora_ML_GCN / Cora_ML_MLP / Cora_ML_GCN_identity_features\n",
    "#url_list = [\"http://localhost:7777/api/graph_info?dataset_id=7&model_id=16&explain_id=4&graph_id=1\",\n",
    "#            \"http://localhost:7777/api/graph_info?dataset_id=7&model_id=17&explain_id=4&graph_id=1\",\n",
    "#            \"http://localhost:7777/api/graph_info?dataset_id=7&model_id=18&explain_id=4&graph_id=1\"\n",
    "#           ]\n",
    "\n",
    "# Cora_GCN / MLP / Cora_GCN_identity_features\n",
    "url_list = [\"http://localhost:7777/api/graph_info?dataset_id=4&model_id=4&explain_id=4&graph_id=1\",\n",
    "            \"http://localhost:7777/api/graph_info?dataset_id=4&model_id=7&explain_id=4&graph_id=1\",\n",
    "            \"http://localhost:7777/api/graph_info?dataset_id=4&model_id=8&explain_id=4&graph_id=1\"\n",
    "           ]\n",
    "# Cora GCN SymNorm tideA / GCN SymNorm A\n",
    "# url_list = [\"http://localhost:7777/api/graph_info?dataset_id=4&model_id=4&explain_id=4&graph_id=1\",\n",
    "#             \"http://localhost:7777/api/graph_info?dataset_id=4&model_id=12&explain_id=4&graph_id=1\"\n",
    "#            ]\n",
    "\n",
    "# Citeseer_GCN / MLP / Giteseer_GCN_identity_features\n",
    "#url_list = [\"http://localhost:7777/api/graph_info?dataset_id=5&model_id=9&explain_id=4&graph_id=1\"\n",
    "#           ,\"http://localhost:7777/api/graph_info?dataset_id=5&model_id=10&explain_id=4&graph_id=1\"\n",
    "#           ,\"http://localhost:7777/api/graph_info?dataset_id=5&model_id=11&explain_id=4&graph_id=1\"\n",
    "#           ]\n",
    "results_list = []\n",
    "obj_list = []\n",
    "score_list = []\n",
    "pred_score_list = []\n",
    "for i in range(len(url_list)):\n",
    "    r = getUrl(url_list[i])\n",
    "    receive_obj = json.loads(r.text)\n",
    "    graph_obj = receive_obj[\"graph_obj\"]\n",
    "    obj_list.append(graph_obj)\n",
    "    results = getClass(graph_obj)\n",
    "    results_list.append(results)\n",
    "    score_list.append(getScoreOnGroundTruth(graph_obj))\n",
    "    pred_score_list.append(getScoreOnPrediction(graph_obj))\n",
    "print(len(results_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Check consistent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Check consistent\n",
    "flag = True\n",
    "for j in range(len(results_list[0][0])):\n",
    "    for i in range(1,len(url_list)):\n",
    "        if results_list[0][0][j] == results_list[i][0][j]:\n",
    "            continue\n",
    "        else:\n",
    "            flag = False\n",
    "            break\n",
    "    if flag:\n",
    "        break\n",
    "if flag:\n",
    "    print(\"consistent\")\n",
    "else:\n",
    "    print(\"not consistent\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Multiple TF Stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Stats = {}\n",
    "def addCount(TF_list):\n",
    "    TF_list = map(lambda x: str(x), TF_list)\n",
    "    fingerprint = \" \".join(TF_list)\n",
    "    if fingerprint in Stats:\n",
    "        Stats[fingerprint] = Stats[fingerprint] + 1\n",
    "    else:\n",
    "        Stats[fingerprint] = 1\n",
    "    \n",
    "for j in range(len(results_list[0][2])):\n",
    "    TF_sublist = []\n",
    "    for i in range(len(url_list)):\n",
    "        TF_sublist.append(results_list[i][2][j])\n",
    "    addCount(TF_sublist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Construct Neighbor Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructNeighborSet(graph_in):\n",
    "    neighbor_set = {}\n",
    "    senders = graph_in[\"senders\"]\n",
    "    receivers = graph_in[\"receivers\"]\n",
    "    for i in range(len(senders)):\n",
    "        send_node = senders[i]\n",
    "        if not send_node in neighbor_set:\n",
    "            neighbor_set[send_node] = []\n",
    "        neighbor_set[send_node].append(receivers[i])\n",
    "    return neighbor_set\n",
    "\n",
    "graph_in = obj_list[0][\"graph_in\"]\n",
    "cora_gcn_neighbor_set = constructNeighborSet(graph_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getStats(nodelist, results_list):\n",
    "    Stats = {}\n",
    "    def addCount(TF_list):\n",
    "        TF_list = map(lambda x: str(x), TF_list)\n",
    "        fingerprint = \" \".join(TF_list)\n",
    "        if fingerprint in Stats:\n",
    "            Stats[fingerprint] = Stats[fingerprint] + 1\n",
    "        else:\n",
    "            Stats[fingerprint] = 1\n",
    "\n",
    "    for j in nodelist:\n",
    "        TF_sublist = []\n",
    "        for i in range(len(results_list)):\n",
    "            TF_sublist.append(results_list[i][2][j])\n",
    "        addCount(TF_sublist)\n",
    "    return Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Extract Special Patterns. cCorrent_nWrong / cWrong_nCorrect."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractSpecialPatternList(TF_class, neighbor_set, center_class, neighbor_class):\n",
    "    specialList = []\n",
    "    for i in range(len(TF_class)):\n",
    "        if TF_class[i] == center_class:\n",
    "            neighbors = neighbor_set[i]\n",
    "            flag = True\n",
    "            for j in range(len(neighbors)):\n",
    "                if not TF_class[neighbors[j]] == neighbor_class:\n",
    "                    flag = False\n",
    "                    break\n",
    "            if flag:\n",
    "                specialList.append(i)\n",
    "    return specialList\n",
    "Special_pattern_cCorrect_nWrong = extractSpecialPatternList(results_list[0][2], cora_gcn_neighbor_set, True, False)\n",
    "Special_pattern_cWrong_nCorrect = extractSpecialPatternList(results_list[0][2], cora_gcn_neighbor_set, False, True)\n",
    "\n",
    "\n",
    "#print(len(Special_pattern_cCorrect_nWrong), len(Special_pattern_cWrong_nCorrect))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printStats(Stats):\n",
    "    for key in Stats:\n",
    "        print(key+\" \"+str((Stats[key])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Degree Stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "%matplotlib inline\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDegreeStatsGraph(Stats, title, key_num=0, enable_legend=False):\n",
    "    x_axis_list = []\n",
    "    y_axis_list = []\n",
    "    legend_name = []\n",
    "    stats_main_key = list(Stats.keys())\n",
    "    #stats_main_key = [stats_main_key[key_num]]\n",
    "    for key in stats_main_key:\n",
    "        legend_name.append(key)\n",
    "        stats_key = Stats[key]\n",
    "        sorted_keys = list(stats_key.keys())\n",
    "        #sorted_keys.sort()\n",
    "        x_axis_list.append(sorted_keys)\n",
    "        y_axis_sublist = []\n",
    "        total_num = 0\n",
    "        for i in sorted_keys:\n",
    "            total_num = total_num + stats_key[i]\n",
    "        for i in sorted_keys:\n",
    "            y_axis_sublist.append(stats_key[i])\n",
    "        y_axis_list.append(y_axis_sublist)\n",
    "    #color = [GREEN,BLUE,PURPLE,LIGHTBLUE,RED,DARKYELLO]\n",
    "    color = [\"#1f77b4\", \"#ff7f0e\", \"#2ca02c\", \"#d62728\", \"#9467bd\", \"#8c564b\", \"#e377c2\", \"#7f7f7f\", \"#bcbd22\", \"#17becf\"]\n",
    "    marker = [\"o\",\"v\",\"s\",\"p\",\"*\",\"h\",\"<\",\">\"]\n",
    "    alpha = [0.9] * 10\n",
    "    fig=plt.figure(figsize=(6,4))\n",
    "    ax1=fig.add_subplot(111)\n",
    "    for i in range(len(legend_name)):\n",
    "        xnew_list = x_axis_list[i]\n",
    "        ynew_list = y_axis_list[i]\n",
    "        ax1.plot(xnew_list,ynew_list,label=legend_name[i],color=color[i],alpha=alpha[i], marker=marker[i])\n",
    "    ax1.set_xlabel(\"Degree\")\n",
    "    ax1.set_ylabel(\"Accuracy\")\n",
    "    ax1.set_title(title+\" \")\n",
    "    #ax1.set_xlim(xmin=0, xmax=30)\n",
    "    #ax1.set_ylim(ymin=0, ymax=1) \n",
    "    #ax1.set_xbound(0, 600)\n",
    "    if enable_legend:\n",
    "        plt.legend(loc='best')\n",
    "    plt.grid()\n",
    "    #plt.show()\n",
    "    #plt.savefig(\"figs/Analysis_{}_{}\".format(title,stats_main_key[0]),dpi=320,quality=100)\n",
    "    plt.savefig(\"figs/Analysis_{}\".format(title),dpi=320,quality=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printDegreeStats(Stats):\n",
    "    for key in Stats:\n",
    "        print(key)\n",
    "        stats_key = Stats[key]\n",
    "        sorted_keys = list(stats_key.keys())\n",
    "        sorted_keys.sort()\n",
    "        for i in sorted_keys:\n",
    "            print(i,stats_key[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighborDegreeStats(nodelist, results_list, neighbor_set):\n",
    "    Stats = {}\n",
    "    def addId(TF_list, node_id):\n",
    "        if len(TF_list)>0:\n",
    "            TF_list = map(lambda x: str(x), TF_list)\n",
    "            fingerprint = \" \".join(TF_list)\n",
    "        else:\n",
    "            fingerprint = \"All\"\n",
    "        degree = len(neighbor_set[node_id])\n",
    "        if degree >= 16:\n",
    "            degree = \">=16\"\n",
    "        if not fingerprint in Stats:\n",
    "            Stats[fingerprint] = {}\n",
    "        if not degree in Stats[fingerprint]:\n",
    "            Stats[fingerprint][degree] = 0\n",
    "        Stats[fingerprint][degree] = Stats[fingerprint][degree] + 1\n",
    "    if len(results_list) == 0:\n",
    "        for j in nodelist:\n",
    "            addId([], j)\n",
    "    else:\n",
    "        for j in nodelist:\n",
    "            TF_sublist = []\n",
    "            for i in range(len(results_list)):\n",
    "                TF_sublist.append(results_list[i][2][j])\n",
    "            addId(TF_sublist, j)\n",
    "    return Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighborStats(nodelist, results_list):\n",
    "    Stats = {}\n",
    "    def addId(TF_list, node_id):\n",
    "        TF_list = map(lambda x: str(x), TF_list)\n",
    "        fingerprint = \" \".join(TF_list)\n",
    "        if fingerprint in Stats:\n",
    "            Stats[fingerprint].append(node_id)\n",
    "        else:\n",
    "            Stats[fingerprint] = [node_id]\n",
    "\n",
    "    for j in nodelist:\n",
    "        TF_sublist = []\n",
    "        for i in range(len(results_list)):\n",
    "            TF_sublist.append(results_list[i][2][j])\n",
    "        addId(TF_sublist, j)\n",
    "    return Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getNeighborsAccuracy(nodeIdList, neighbor_set, TF_class):\n",
    "    neighbor_accuracy = []\n",
    "    for i in range(len(nodeIdList)):\n",
    "        nodeid = nodeIdList[i]\n",
    "        neighbor_num = len(neighbor_set[nodeid])\n",
    "        neighbor_correct_num = 0\n",
    "        for j in range(len(neighbor_set[nodeid])):\n",
    "            neighbor_id = neighbor_set[nodeid][j]\n",
    "            if TF_class[neighbor_id]:\n",
    "                neighbor_correct_num = neighbor_correct_num + 1\n",
    "        neighbor_acc = neighbor_correct_num / neighbor_num\n",
    "        neighbor_accuracy.append(neighbor_acc)\n",
    "    return neighbor_accuracy\n",
    "\n",
    "def getNeighborStr(accuracy):\n",
    "    node_num = len(accuracy)\n",
    "    sum_acc = 0\n",
    "    for i in range(node_num):\n",
    "        sum_acc = sum_acc + accuracy[i]\n",
    "    avg_acc = sum_acc / node_num\n",
    "    return str(avg_acc)\n",
    "\n",
    "\n",
    "def printNeighborStats(Stats, neighbor_set, results_list):\n",
    "    #print(\"Cora_GCN Cora_MLP Cora_GCN_identity_feature Nodenum Cora_GCN_Neighbor_Mean_accuracy Cora_MLP_Neighbor_Mean_accuracy Cora_GCN_identity_feature_Neighbor_Mean_accuracy\")\n",
    "    for key in Stats:\n",
    "        print(key+\" \"+str(Stats[key]))\n",
    "        #gcn_neighbor_acc = getNeighborsAccuracy(Stats[key],neighbor_set, results_list[0][2])\n",
    "        #mlp_neighbor_acc = getNeighborsAccuracy(Stats[key],neighbor_set, results_list[1][2])\n",
    "        #gcn_identity_neighbor_acc = getNeighborsAccuracy(Stats[key],neighbor_set, results_list[2][2])\n",
    "        #print(key+\" \"+str(len(Stats[key]))+\" \"+getNeighborStr(gcn_neighbor_acc)+\" \"+getNeighborStr(mlp_neighbor_acc)+\" \"+getNeighborStr(gcn_identity_neighbor_acc))\n",
    "        #print(\"GCN neighbor: \",  getNeighborsAccuracy(Stats[key],neighbor_set, results_list[0][2]))\n",
    "        #print(\"MLP neighbor: \", getNeighborsAccuracy(Stats[key],neighbor_set, results_list[1][2]))\n",
    "        #print(\"GCN Identity neighbor: \", getNeighborsAccuracy(Stats[key],neighbor_set, results_list[2][2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_num = len(cora_gcn_neighbor_set.keys())\n",
    "\n",
    "model_name = [\"GCN SymNorm tideA\", \"GCN SymNorm A\"]\n",
    "selected_model_permutation = [\n",
    "    [], [1]\n",
    "]\n",
    "for selected_model in selected_model_permutation:\n",
    "    selected_results_list = []\n",
    "    finger = \"\"\n",
    "    for i in range(len(selected_model)):\n",
    "        finger = finger + model_name[selected_model[i]] + \" \"\n",
    "        selected_results_list.append(results_list[selected_model[i]])\n",
    "    stats = getNeighborDegreeStats(range(node_num), selected_results_list, cora_gcn_neighbor_set)\n",
    "    print(stats)\n",
    "\n",
    "    for i in range(len(list(stats.keys()))):\n",
    "        getDegreeStatsGraph(stats,finger,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_num = len(cora_gcn_neighbor_set.keys())\n",
    "\n",
    "model_name = [\"GCN\", \"MLP\", \"GCN_identity_feature\"]\n",
    "selected_model_permutation = [\n",
    "    [], [0], [1], [2], [0,1], [0,2], [1,2], [0,1,2]\n",
    "]\n",
    "for selected_model in selected_model_permutation:\n",
    "    selected_results_list = []\n",
    "    finger = \"\"\n",
    "    for i in range(len(selected_model)):\n",
    "        finger = finger + model_name[selected_model[i]] + \" \"\n",
    "        selected_results_list.append(results_list[selected_model[i]])\n",
    "    stats = getNeighborDegreeStats(range(node_num), selected_results_list, cora_gcn_neighbor_set)\n",
    "    print(stats)\n",
    "\n",
    "    for i in range(len(list(stats.keys()))):\n",
    "        getDegreeStatsGraph(stats,finger,i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDegreeAcuracyStats(stats):\n",
    "    accuracy_stats = {}\n",
    "    true_stats = stats[\"True\"]\n",
    "    false_stats = stats[\"False\"]\n",
    "    degree_key = list(set().union(true_stats.keys(), false_stats.keys()))\n",
    "    for degree in degree_key:\n",
    "        true_num = true_stats.get(degree)\n",
    "        false_num = false_stats.get(degree)\n",
    "        if not true_num:\n",
    "            true_num = 0\n",
    "        if not false_num:\n",
    "            false_num = 0\n",
    "        total = true_num + false_num\n",
    "        accuracy = true_num / total\n",
    "        accuracy_stats[degree] = accuracy\n",
    "    #print(accuracy_stats)\n",
    "    return accuracy_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_num = len(cora_gcn_neighbor_set.keys())\n",
    "\n",
    "model_name = [\"GCN\", \"MLP\", \"GCN_identity_feature\"]\n",
    "selected_model_permutation = [\n",
    "    [0], [1], [2]\n",
    "]\n",
    "selected_stats = {}\n",
    "for selected_model in selected_model_permutation:\n",
    "    selected_results_list = []\n",
    "    finger = \"\"\n",
    "    for i in range(len(selected_model)):\n",
    "        finger = finger + model_name[selected_model[i]] + \" \"\n",
    "        selected_results_list.append(results_list[selected_model[i]])\n",
    "    model_name_local = model_name[selected_model[0]]\n",
    "    stats = getNeighborDegreeStats(range(node_num), selected_results_list, cora_gcn_neighbor_set)\n",
    "    #print(stats)\n",
    "    accuracy_stats = getDegreeAcuracyStats(stats)\n",
    "    selected_stats[model_name_local] = accuracy_stats\n",
    "getDegreeStatsGraph(selected_stats,\"\",i,enable_legend=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "neighbor_stats_special_pattern_cCorrect_nWrong = getNeighborStats(Special_pattern_cCorrect_nWrong, results_list)\n",
    "printNeighborStats(neighbor_stats_special_pattern_cCorrect_nWrong, cora_gcn_neighbor_set, results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "neighbor_stats_special_pattern_cWrong_nCorrect = getNeighborStats(Special_pattern_cWrong_nCorrect, results_list)\n",
    "printNeighborStats(neighbor_stats_special_pattern_cWrong_nCorrect, cora_gcn_neighbor_set, results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getDegreeFromList(nodelist, neighbor_set):\n",
    "    for i in nodelist:\n",
    "        print(i, len(neighbor_set[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodelist =[394, 1945, 2045, 2180, 2434, 2503, 2532]\n",
    "getDegreeFromList(nodelist, cora_gcn_neighbor_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "graph_obj = obj_list[0]\n",
    "train_mask = graph_obj[\"mask\"][\"train\"]\n",
    "node_num = len(cora_gcn_neighbor_set.keys())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. Shortest Path Distance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "def getShortestPathDistance(node_num, neighbor_set, anchor_list):\n",
    "    shortest_path_list = []\n",
    "    anchor_set = set(anchor_list)\n",
    "    for i in range(node_num):\n",
    "        if i == 633:\n",
    "            debug_flag = True\n",
    "        else:\n",
    "            debug_flag = False\n",
    "        de = collections.deque([[i,0]])\n",
    "        shortest_path_distance = \"inf\"\n",
    "        mask = [False for i in range(node_num)]\n",
    "        while len(de)>0:\n",
    "            curr = de.popleft()\n",
    "            if debug_flag:\n",
    "                print(curr)\n",
    "            mask[curr[0]] = True\n",
    "            if curr[0] in anchor_set:\n",
    "                shortest_path_distance = curr[1]\n",
    "                break\n",
    "            else:\n",
    "                neighbors = neighbor_set[curr[0]]\n",
    "                for j in neighbors:\n",
    "                    if not mask[j]:\n",
    "                        de.append([j, curr[1]+1])\n",
    "        shortest_path_list.append(shortest_path_distance)\n",
    "    return shortest_path_list\n",
    "\n",
    "shortest_path_list = getShortestPathDistance(node_num, cora_gcn_neighbor_set, train_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections \n",
    "def getShortestPathDistanceSet(node_num, neighbor_set, anchor_list):\n",
    "    shortest_path_list = []\n",
    "    anchor_set = set(anchor_list)\n",
    "    for i in range(node_num):\n",
    "        if i == 633:\n",
    "            debug_flag = True\n",
    "        else:\n",
    "            debug_flag = False\n",
    "        de = collections.deque([[i,0]])\n",
    "        shortest_path_distance = \"inf\"\n",
    "        shortest_path_set = []\n",
    "        mask = [False for i in range(node_num)]\n",
    "        while len(de)>0:\n",
    "            curr = de.popleft()\n",
    "            if debug_flag:\n",
    "                print(curr)\n",
    "            mask[curr[0]] = True\n",
    "            if curr[0] in anchor_set:\n",
    "                if shortest_path_distance == \"inf\":\n",
    "                    shortest_path_distance = curr[1]\n",
    "                    shortest_path_set.append(curr[0])\n",
    "                elif shortest_path_distance == curr[1]:\n",
    "                    shortest_path_set.append(curr[0])\n",
    "                else:\n",
    "                    break\n",
    "            else:\n",
    "                neighbors = neighbor_set[curr[0]]\n",
    "                for j in neighbors:\n",
    "                    if not mask[j]:\n",
    "                        de.append([j, curr[1]+1])\n",
    "        shortest_path_list.append({\n",
    "            \"shortest_path_distance\":shortest_path_distance,\n",
    "            \"shortest_path_set\":list(set(shortest_path_set))\n",
    "        })\n",
    "    return shortest_path_list\n",
    "\n",
    "shortest_path_list = getShortestPathDistanceSet(node_num, cora_gcn_neighbor_set, train_mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def printPathStats(current_node, stats,labels):\n",
    "    print(\"Current Node\", current_node)\n",
    "    \n",
    "    print(\"Shortest path distance\", stats[current_node][\"shortest_path_distance\"])\n",
    "    short_set = stats[current_node][\"shortest_path_set\"]\n",
    "    print(\"Node_Id  Ground Truth  Predict  T/F\")\n",
    "    print(\"Current Node\")\n",
    "    print(current_node,\"\\t\",labels[0][current_node], \"\\t\\t\", labels[1][current_node], \"\\t\", labels[2][current_node])\n",
    "    print(\"Train Node\")\n",
    "    for key in short_set:\n",
    "        print(key,\"\\t\",labels[0][key], \"\\t\\t\", labels[1][key], \"\\t\", labels[2][key])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "printPathStats(1378, shortest_path_list,results_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getShortestPathDict(shortest_path_list, TF_class):\n",
    "    shortest_path_dict = {}\n",
    "    for i in range(len(shortest_path_list)):\n",
    "        sp = shortest_path_list[i]\n",
    "        tf = str(TF_class[i])\n",
    "        if not sp in shortest_path_dict:\n",
    "            shortest_path_dict[sp] = {\n",
    "                \"True\":0,\n",
    "                \"False\":0\n",
    "            }\n",
    "        shortest_path_dict[sp][str(tf)] = shortest_path_dict[sp][str(tf)] + 1\n",
    "    return shortest_path_dict\n",
    "        \n",
    "shortest_path_dict = getShortestPathDict(shortest_path_list, results_list[0][2])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in shortest_path_dict:\n",
    "    print(i, shortest_path_dict[i][\"True\"], shortest_path_dict[i][\"False\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructNeighborSet(graph_in):\n",
    "    neighbor_set = {}\n",
    "    senders = graph_in[\"senders\"]\n",
    "    receivers = graph_in[\"receivers\"]\n",
    "    for i in range(len(senders)):\n",
    "        send_node = senders[i]\n",
    "        if not send_node in neighbor_set:\n",
    "            neighbor_set[send_node] = []\n",
    "        neighbor_set[send_node].append(receivers[i])\n",
    "    return neighbor_set\n",
    "\n",
    "graph_in = obj_list[0][\"graph_in\"]\n",
    "cora_gcn_neighbor_set = constructNeighborSet(graph_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_selection = 0\n",
    "TF_class = results_list[model_selection][2]\n",
    "node_num = len(cora_gcn_neighbor_set.keys())\n",
    "\n",
    "pred_score_dict = {}\n",
    "pred_score_dict[str(True)]=0\n",
    "pred_score_dict[str(False)]=0\n",
    "TrueNum = 0\n",
    "FalseNum = 0\n",
    "pd_score_list =pred_score_list[model_selection]\n",
    "count = 0 \n",
    "for i in range(node_num):\n",
    "    pred_score = pd_score_list[i]\n",
    "    pred_score_dict[str(TF_class[i])] = pred_score_dict[str(TF_class[i])] + pred_score\n",
    "    if TF_class[i]:\n",
    "        TrueNum = TrueNum + 1\n",
    "    else:\n",
    "        if pred_score < 0.5:\n",
    "            print(i, pred_score)\n",
    "            count = count + 1\n",
    "        FalseNum = FalseNum + 1\n",
    "        #if pred_score>0.5:\n",
    "        #    print(i, pred_score)\n",
    "pred_score_dict[str(True)] = pred_score_dict[str(True)]  / TrueNum\n",
    "pred_score_dict[str(False)] = pred_score_dict[str(False)]  / FalseNum\n",
    "print(pred_score_dict)\n",
    "print(TrueNum, FalseNum, count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## GCN for Cora-ML\n",
    "# Pred Score List\n",
    "# {'True': 0.5891725559627756, 'False': 0.3584966339494871}\n",
    "# Ground Truth List\n",
    "# {'True': 0.5891725559627756, 'False': 0.18541575310265887}\n",
    "\n",
    "\n",
    "# MLP\n",
    "# Pred Score List\n",
    "# {'True': 0.581954779419416, 'False': 0.36661832975616526}\n",
    "\n",
    "\n",
    "# GCN_Identity_features\n",
    "# Pred Score List\n",
    "# {'True': 0.3290714873580271, 'False': 0.22680015858059818}\n",
    "\n",
    "\n",
    "# GCN for Cora\n",
    "# Pred Score List\n",
    "# {'True': 0.7961086297035217, 'False': 0.5451021153391815}\n",
    "# True False True>0.9 False>0.9\n",
    "# 2200 508 896  21\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"NodeId\\tGCN - MLP\")\n",
    "node_num = len(cora_gcn_neighbor_set.keys())\n",
    "score_diff = []\n",
    "for i in range(node_num):\n",
    "    #print(i,\"\\t\", score_list[0][i] - score_list[1][i])\n",
    "    score_diff.append(score_list[0][i] - score_list[1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"whitegrid\")\n",
    "ax = sns.distplot(score_diff,kde=False)\n",
    "fig = ax.get_figure()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
