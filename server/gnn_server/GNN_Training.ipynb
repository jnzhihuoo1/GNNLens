{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Args and Import."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch_geometric'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-7cbcd837d5de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptim\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mGCN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset_seed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data2/zhihua/github/GNNLens/server/gnn_server/models.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtorch_geometric\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpyg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#import yaml\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'torch_geometric'"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import argparse\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from models import GCN\n",
    "from sklearn.metrics import f1_score\n",
    "from utils import accuracy, set_seed\n",
    "\n",
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\"\n",
    "\n",
    "parser = argparse.ArgumentParser(formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "parser.add_argument('--epochs',type=int,default=200,help='Number of epochs to train')\n",
    "parser.add_argument('--seed',type=int,default=42,help='random seed')\n",
    "parser.add_argument('--lr',type=float,default=0.01,help='Initial learning rate,adam:0.001,sgd:0.05')\n",
    "parser.add_argument('--weight_decay',type=float,default=5e-4,help='weight decay') #5e-4\n",
    "parser.add_argument('--hidden',type=int,default=16,help='Number of hidden units')\n",
    "parser.add_argument('--dropout',type=float,default=0.5,help='Dropout rate')\n",
    "parser.add_argument('--dataset',type=str,default='Cora',help='name of dataset:Cora')\n",
    "parser.add_argument('--optimize_type',type=str,default='Adam', help='Optimization method, Adam; SGD')\n",
    "parser.add_argument('--model_name',type=str,default='GCN',help='name of model:GCN')\n",
    "parser.add_argument('--norm_type',type=str,default='SymNorm_tildeA',help= 'Normalization method:SymNorm_tildeA')\n",
    "parser.add_argument('--layer_num',type=int,default=6,help='layer num for GCN_nlayer')\n",
    "parser.add_argument('--data_path', type=str,default='../data/', help='the path for dataset')\n",
    "args = parser.parse_args(args=[])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-a5454265cc4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "print(args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'networkx'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-5f7fbfd63e6d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mdataloader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_citation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_citation_v2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mload_citation_v3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mnorm_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm_type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/data2/zhihua/github/GNNLens/server/gnn_server/dataloader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mnetworkx\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mperf_counter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'networkx'"
     ]
    }
   ],
   "source": [
    "from dataloader import load_citation, load_citation_v2, load_citation_v3\n",
    "import time\n",
    "start_time = time.time()\n",
    "dataf = args.data_path\n",
    "norm_type = args.norm_type\n",
    "#norm_type = \"sym_normalized_A\"\n",
    "original_graph, L, features, labels, idx_train,idx_val, idx_test, data_package = load_citation_v3(dataf,\n",
    "                                                                                                  args.dataset,\n",
    "                                                                                                  norm_type=norm_type,\n",
    "                                                                                                  cuda=True, \n",
    "                                                                                                  identity_features=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_node = features.shape[0]\n",
    "print('num_node:',features.shape[0])\n",
    "num_feature = features.shape[1]  \n",
    "print('num_feature: ',features.shape[1])\n",
    "num_class = labels.max().item()+1\n",
    "print('num_class',num_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_train = [i for i in range(num_node)]\n",
    "idx_train = torch.LongTensor(split_train).cuda()\n",
    "idx_test = torch.LongTensor(split_train).cuda()\n",
    "idx_valid = torch.LongTensor(split_train).cuda()\n",
    "print(idx_train.shape, idx_test.shape, idx_valid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Model and Optimizer Initialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 网络加深，反而效果差了\n",
    "print(num_feature, args.hidden, num_class, args.dropout, args.layer_num, True)\n",
    "if args.model_name == 'GCN':\n",
    "    model = GCN( num_feature,args.hidden,num_class,args.dropout,bias=True).cuda()\n",
    "else:\n",
    "    raise Exception('Invalid model:',args.model_name)\n",
    "if args.optimize_type == \"Adam\":\n",
    "    optimizer = optim.Adam(model.parameters(),lr=args.lr,weight_decay=args.weight_decay)\n",
    "else:\n",
    "    optimizer = optim.SGD(model.parameters(),lr=args.lr,weight_decay=args.weight_decay)\n",
    "print('model:%s, Norm:%s, optimizer: %s, hidden:%d'% (args.model_name, args.norm_type,args.optimize_type,args.hidden))\n",
    "print(model)\n",
    "def count_parameters(model):\n",
    "    total_param = 0\n",
    "    for name, param in model.named_parameters():\n",
    "        if param.requires_grad:\n",
    "            num_param = np.prod(param.size())\n",
    "            if param.dim() > 1:\n",
    "                print(name, ':', 'x'.join(str(x) for x in list(param.size())), '=', num_param)\n",
    "            else:\n",
    "                print(name, ':', num_param)\n",
    "            total_param += num_param\n",
    "    return total_param\n",
    "print(count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def test(model, idx_test):\n",
    "    model.eval()\n",
    "    output = model(features,L)\n",
    "    loss_test = F.nll_loss(output[idx_test],labels[idx_test])\n",
    "    acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "    print(loss_test.item(), acc_test.item())\n",
    "\n",
    "def train(model, idx_train, idx_val):\n",
    "\n",
    "    start = time.time()\n",
    "    for epoch in range(args.epochs):\n",
    "        t = time.time()\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        output = model(features,L)\n",
    "        loss_train = F.nll_loss(output[idx_train],labels[idx_train])\n",
    "        acc_train = accuracy(output[idx_train],labels[idx_train])\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "        model.eval()\n",
    "        output = model(features,L)\n",
    "        loss_val = F.nll_loss(output[idx_val],labels[idx_val])\n",
    "        acc_val = accuracy(output[idx_val],labels[idx_val])\n",
    "        #label = labels[idx_val].cpu()\n",
    "        #output = output[idx_val].max(1)[1].type_as(labels).cpu()\n",
    "        #f1_val  = f1_score(label.numpy(),output.numpy(), average=\"micro\")\n",
    "        take_time = time.time()-t\n",
    "        print(\"Epoch : {}, Time : {}, Val_loss: {}, Val_Acc: {}\".format(epoch, take_time, loss_val.item(), acc_val.item()))\n",
    "    \n",
    "\n",
    "print(\"start training----\")\n",
    "for i in range(1):\n",
    "    print(i)\n",
    "    train(model, idx_train, idx_valid)\n",
    "    test(model, idx_test)\n",
    "print('finish------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training GCN with all data in Cora.\n",
    "Epoch : 199, Time : 0.010625362396240234, Val_loss: 0.129765585064888, Val_Acc: 0.9623338257016248\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Save and Load Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gcn_identity_features_photo.pkt\"\n",
    "torch.save(model, model_path)\n",
    "model = torch.load(model_path)\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gcn_identity_features_photo_state.pkt\"\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gcn_photo.pkt\"\n",
    "model = torch.load(model_path)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Hook Model Definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "from torch.nn.parameter import Parameter\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.modules.module import Module\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import skcuda.linalg as sklin\n",
    "from layer import GCN_layer, BiGCN1_layer, BiGCN2_layer, BiGCN3_layer \n",
    "\n",
    "'''\n",
    "GCN_layer(ind,outd,bias=True)\n",
    "BiGCN1_layer(ind,outd,p,bias=True,beta=True,A2='cos_A2',n_iter=2)  \n",
    "BiGCN2_layer(ind,outd,bias=True, beta=True, A2=None)\n",
    "BiGCN3_layer(ind,outd,bias=True, beta=True, A2=None)\n",
    "--A2 cos_A2/learn_A2/None\n",
    "'''\n",
    "\n",
    "class GCN_hook(nn.Module):\n",
    "    def __init__(self, num_feature,num_hidden,num_class,dropout,bias=True):\n",
    "        super(GCN_hook,self).__init__()\n",
    "\n",
    "        self.gc1 = GCN_layer(num_feature, num_hidden)\n",
    "        self.gc2 = GCN_layer(num_hidden, num_class)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x1 = F.dropout(x, self.dropout, training=self.training)\n",
    "        x2 = self.gc2(x1, adj)\n",
    "        return F.log_softmax(x2, dim=1), x1\n",
    "\n",
    "class GCN_3layer_hook(nn.Module):\n",
    "    def __init__(self, num_feature,num_hidden,num_class,dropout,bias=True):\n",
    "        super(GCN_3layer_hook,self).__init__()\n",
    "\n",
    "        self.gc1 = GCN_layer(num_feature, num_hidden)\n",
    "        self.gc2 = GCN_layer(num_hidden, num_hidden)\n",
    "        self.gc3 = GCN_layer(num_hidden, num_class)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        x = F.relu(self.gc1(x, adj))\n",
    "        x1 = F.dropout(x, self.dropout, training=self.training)\n",
    "        x2 = F.relu(self.gc2(x1, adj))\n",
    "        x2 = F.dropout(x2, self.dropout, training=self.training)\n",
    "        x3 = self.gc3(x2, adj)\n",
    "        return F.log_softmax(x3, dim=1), x1,x2\n",
    "    \n",
    "class GCN_nlayer_hook(nn.Module):\n",
    "    def __init__(self, num_feature,num_hidden,num_class,dropout,layer_num=2,bias=True):\n",
    "        super(GCN_nlayer_hook,self).__init__()\n",
    "        self.layer_num = layer_num\n",
    "        self.gc_input = GCN_layer(num_feature, num_hidden)\n",
    "        if layer_num > 2:\n",
    "            self.gc_inner = nn.ModuleList([GCN_layer(num_hidden, num_hidden) for i in range(layer_num-2)])        \n",
    "        self.gc_output = GCN_layer(num_hidden, num_class)\n",
    "        self.dropout = dropout\n",
    "\n",
    "    def forward(self, x, adj):\n",
    "        inner_state = []\n",
    "        x = F.relu(self.gc_input(x, adj))\n",
    "        x = F.dropout(x, self.dropout, training=self.training)\n",
    "        inner_state.append(x)\n",
    "        if self.layer_num > 2:\n",
    "            for i in range(self.layer_num - 2):\n",
    "                x = self.gc_inner[i](x,adj)\n",
    "                x = F.dropout(x, self.dropout, training=self.training)\n",
    "                inner_state.append(x)\n",
    "        x = self.gc_output(x, adj)\n",
    "        return F.log_softmax(x, dim=1), inner_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gcn_cora_%dlayer_symnorm_state.pkt\".format(6)\n",
    "#torch.save(model.state_dict(), model_path)\n",
    "args_input = [1433,16,7,0.5]\n",
    "kwargs = {\n",
    "    \"layer_num\": 6,\n",
    "    \"bias\": True\n",
    "}\n",
    "model = GCN_nlayer_hook(*args_input,**kwargs).cuda()\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "output, inner_state = model(features,L)\n",
    "loss_test = F.nll_loss(output[idx_test],labels[idx_test])\n",
    "acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "print(loss_test.item(), acc_test.item())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"gcn_identity_features_cora.pkt\"\n",
    "model = torch.load(model_path)\n",
    "model.eval()\n",
    "output = model(features,L)\n",
    "loss_test = F.nll_loss(output[idx_test],labels[idx_test])\n",
    "acc_test = accuracy(output[idx_test],labels[idx_test])\n",
    "print(loss_test.item(), acc_test.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Hidden State Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.manifold import TSNE\n",
    "import seaborn as sns; sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "def dimension_reduction(input_array):\n",
    "    start_time = time.time()\n",
    "    X = np.array(input_array)    \n",
    "    X_embedded = TSNE(n_components=2).fit_transform(X)\n",
    "    print(time.time() - start_time)\n",
    "    return X_embedded\n",
    "def visualize(embedded_array,labels):\n",
    "    \n",
    "    #sns.set_palette(sns.color_palette(\"Paired\"))\n",
    "    X = np.array(embedded_array)\n",
    "    labels = np.array(labels)\n",
    "    labels = np.expand_dims(labels, axis=1)\n",
    "    data = np.concatenate((X, labels), axis=1)\n",
    "    df = pd.DataFrame(data, columns=[\"x\", \"y\",\"Labels\"])\n",
    "    # Create an array with the colors you want to use\n",
    "    colors = [\"#FF0B04\", \"#4374B3\"]\n",
    "    # Set your custom color palette\n",
    "    customPalette = sns.set_palette(sns.color_palette(colors))\n",
    "    ax = sns.scatterplot(x=\"x\", y=\"y\",hue=\"Labels\", data=df, palette=\"Set1\", legend=False)\n",
    "    \n",
    "current_palette = sns.color_palette()\n",
    "sns.palplot(current_palette)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Output\n",
    "input_array = output.cpu().detach().numpy()\n",
    "labels_array = labels.cpu().detach().numpy()\n",
    "embedded_array = dimension_reduction(input_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Input\n",
    "features_array = features.cpu().detach().numpy()\n",
    "features_embeddded_array = dimension_reduction(features_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer2\n",
    "inner_embedded_array = []\n",
    "labels_array = labels.cpu().detach().numpy()\n",
    "\n",
    "for i in range(len(inner_state)):\n",
    "    layer2 = inner_state[i]\n",
    "    layer2_array = layer2.cpu().detach().numpy()\n",
    "    layer2_embeddded_array = dimension_reduction(layer2_array)\n",
    "    inner_embedded_array.append(layer2_embeddded_array)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Layer3\n",
    "layer3_array = layer3.cpu().detach().numpy()\n",
    "layer3_embeddded_array = dimension_reduction(layer3_array)\n",
    "labels_array = labels.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(embedded_array, labels.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize(inner_embedded_array[3], labels.cpu().detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(layer2_embeddded_array)\n",
    "import pickle as pkl\n",
    "with open(\"cora_tsne_hidden.pkt\",\"wb\") as f:\n",
    "    pkl.dump(layer2_embeddded_array, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
