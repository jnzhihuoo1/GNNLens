{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load Data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import json\n",
    "\n",
    "def getUrl(url):\n",
    "    r = requests.get(url)\n",
    "    return r\n",
    "def load_data(dataset_id):\n",
    "    #for dataset_id in [4,4]:\n",
    "    start_time = time.time()\n",
    "    url_list = [\"http://localhost:7777/api/graph_bundle_info?dataset_id={}\".format(dataset_id)]\n",
    "    r = getUrl(url_list[0])\n",
    "    duration_time = time.time() - start_time\n",
    "    #print(duration_time)\n",
    "    #print(len(r.text))\n",
    "    receive_obj = json.loads(r.text)\n",
    "    #print(receive_obj.keys())\n",
    "    \n",
    "    if receive_obj[\"success\"] == True:\n",
    "        graph_obj = receive_obj[\"graph_obj\"]\n",
    "        #graph_obj = decompress_data(receive_obj[\"graph_obj\"])\n",
    "        print(graph_obj[\"common\"][\"name\"], duration_time)\n",
    "        #print(receive_obj[\"graph_obj\"].keys())\n",
    "        pass\n",
    "    else:\n",
    "        print(\"Not success dataset_id:{} time:{}\".format(dataset_id, duration_time))\n",
    "    return graph_obj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Inconsistency Analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def getMajorLabelList(Info):\n",
    "    max_value = max(Info['train_nodes'])\n",
    "    label_list = [i for i,j in enumerate(Info['train_nodes']) if j==max_value]\n",
    "    return label_list\n",
    "def error_distribution_analysis(ground_truth, model_output):\n",
    "    total_node_num = len(ground_truth)\n",
    "    error_num = 0\n",
    "    \n",
    "    for i in range(total_node_num):\n",
    "        gt = ground_truth[i]\n",
    "        mo = model_output[i]\n",
    "        if not gt == mo:\n",
    "            error_num = error_num + 1\n",
    "    #print(\"Error Distribution:\")\n",
    "    #print(\"Error:{} ({}) Correct:{} ({}) Total:{} \".format(error_num, error_num / total_node_num\n",
    "    #                                                          , total_node_num - error_num, 1- error_num / total_node_num,\n",
    "    #                                                          total_node_num))\n",
    "    return [error_num, error_num / total_node_num\n",
    "                                                              , total_node_num - error_num, 1- error_num / total_node_num,\n",
    "                                                              total_node_num]\n",
    "def Inconsistency_error_pattern_analysis(ground_truth, major_label_dict, model_output):\n",
    "    total_node_num = len(ground_truth)\n",
    "    second_satisfied_nodes = 0\n",
    "    third_satisfied_nodes = 0\n",
    "    for i in range(total_node_num):\n",
    "        if i in major_label_dict.keys():\n",
    "            ## Pass the first condition, unique major label.\n",
    "            ## Judge whether it is inconsistency.\n",
    "            gt = ground_truth[i]\n",
    "            mj = major_label_dict[i]\n",
    "            if not gt == mj:\n",
    "                ## Pass the second condition, inconsistency.\n",
    "                second_satisfied_nodes = second_satisfied_nodes + 1\n",
    "                mo = model_output[i]\n",
    "                if not gt == mo:\n",
    "                    ## Pass the third condition, error.\n",
    "                    third_satisfied_nodes = third_satisfied_nodes + 1\n",
    "    if second_satisfied_nodes > 0:\n",
    "        #error_distribution_analysis(ground_truth, model_output)\n",
    "        #print(\"Inconsistency Analysis:\")\n",
    "        #print(\"Error:{} ({}) Correct:{} ({}) Total:{} \".format(third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "        #                                                      , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "        #                                                      second_satisfied_nodes))\n",
    "        return [third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "                                                              , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "                                                              second_satisfied_nodes]\n",
    "    else:\n",
    "        print(\"Not found.\")\n",
    "        return []\n",
    "    \n",
    "def Multiple_inconsistency_error_pattern_analysis(ground_truth, major_label_dict,KFS_major_label_dict, model_output):\n",
    "    total_node_num = len(ground_truth)\n",
    "    second_satisfied_nodes = 0\n",
    "    third_satisfied_nodes = 0\n",
    "    for i in range(total_node_num):\n",
    "        if i in major_label_dict.keys() and i in KFS_major_label_dict:\n",
    "            ## Pass the first condition, unique major label.\n",
    "            ## Judge whether it is inconsistency.\n",
    "            gt = ground_truth[i]\n",
    "            mj = major_label_dict[i]\n",
    "            mj2 = KFS_major_label_dict[i]\n",
    "            if (not gt == mj) and (not gt == mj2):\n",
    "                ## Pass the second condition, inconsistency.\n",
    "                second_satisfied_nodes = second_satisfied_nodes + 1\n",
    "                mo = model_output[i]\n",
    "                if not gt == mo:\n",
    "                    ## Pass the third condition, error.\n",
    "                    third_satisfied_nodes = third_satisfied_nodes + 1\n",
    "    if second_satisfied_nodes > 0:\n",
    "        error_distribution_analysis(ground_truth, model_output)\n",
    "        #print(\"Inconsistency Analysis:\")\n",
    "        #print(\"Error:{} ({}) Correct:{} ({}) Total:{} \".format(third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "        #                                                      , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "        #                                                      second_satisfied_nodes))\n",
    "        return [third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "                                                              , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "                                                              second_satisfied_nodes]\n",
    "    else:\n",
    "        print(\"Not found.\")\n",
    "        return []\n",
    "    #return third_satisfied_nodes, second_satisfied_nodes\n",
    "    \n",
    "def Comprehensive_error_pattern_analysis(ground_truth, major_label_dict,KFS_major_label_dict,CGTNGT_list,CGTNGT_threshold,Distance_list, model_output):\n",
    "    total_node_num = len(ground_truth)\n",
    "    second_satisfied_nodes = 0\n",
    "    third_satisfied_nodes = 0\n",
    "    second_satisfied_nodes_list = []\n",
    "    for i in range(total_node_num):\n",
    "        if i in major_label_dict.keys() and i in KFS_major_label_dict:\n",
    "            ## Pass the first condition, unique major label.\n",
    "            ## Judge whether it is inconsistency.\n",
    "            gt = ground_truth[i]\n",
    "            mj = major_label_dict[i]\n",
    "            mj2 = KFS_major_label_dict[i]\n",
    "            CGTNGT = CGTNGT_list[i]\n",
    "            Distance = Distance_list[i]\n",
    "            if (not gt == mj) and (not gt == mj2) and CGTNGT <=CGTNGT_threshold and Distance<=1:\n",
    "                ## Pass the second condition, inconsistency.\n",
    "                second_satisfied_nodes = second_satisfied_nodes + 1\n",
    "                mo = model_output[i]\n",
    "                second_satisfied_nodes_list.append(i)\n",
    "                if not gt == mo:\n",
    "                    ## Pass the third condition, error.\n",
    "                    third_satisfied_nodes = third_satisfied_nodes + 1\n",
    "    if second_satisfied_nodes > 0:\n",
    "        error_distribution_analysis(ground_truth, model_output)\n",
    "        print(\"Inconsistency Analysis:\")\n",
    "        print(\"Error:{} ({}) Correct:{} ({}) Total:{} \".format(third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "                                                              , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "                                                              second_satisfied_nodes))\n",
    "        print(second_satisfied_nodes_list)\n",
    "        return [third_satisfied_nodes, third_satisfied_nodes / second_satisfied_nodes\n",
    "                                                              , second_satisfied_nodes - third_satisfied_nodes, 1- third_satisfied_nodes / second_satisfied_nodes,\n",
    "                                                              second_satisfied_nodes]\n",
    "    else:\n",
    "        print(\"Not found.\")\n",
    "        return []\n",
    "    #return third_satisfied_nodes, second_satisfied_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def constructNeighborSet(graph_in):\n",
    "    neighbor_set = {}\n",
    "    senders = graph_in[\"senders\"]\n",
    "    receivers = graph_in[\"receivers\"]\n",
    "    for i in range(len(senders)):\n",
    "        send_node = senders[i]\n",
    "        if not send_node in neighbor_set:\n",
    "            neighbor_set[send_node] = []\n",
    "        neighbor_set[send_node].append(receivers[i])\n",
    "    return neighbor_set\n",
    "def constructDegreeList(neighbor_set, total_node_num):\n",
    "    degree_list = []\n",
    "    for i in range(total_node_num):\n",
    "        if i in neighbor_set:\n",
    "            degree = len(neighbor_set[i])\n",
    "            degree_list.append(degree)\n",
    "        else:\n",
    "            degree_list.append(0)\n",
    "    return degree_list\n",
    "def constructCGTNGTList(ground_truth,neighbor_set,total_node_num):\n",
    "    CGTNGT_list = []\n",
    "    for i in range(total_node_num):\n",
    "        if i in neighbor_set:\n",
    "            neighbors = neighbor_set[i]\n",
    "            center_label = ground_truth[i]\n",
    "            total = len(neighbors)\n",
    "            count = 0\n",
    "            for neighbor_index in neighbors:\n",
    "                neighbor_label = ground_truth[neighbor_index]\n",
    "                if neighbor_label == center_label:\n",
    "                    count = count + 1\n",
    "            if total > 0:\n",
    "                CGTNGT = count / total\n",
    "            else:\n",
    "                CGTNGT = 0\n",
    "        else:\n",
    "            CGTNGT = 0\n",
    "        CGTNGT_list.append(CGTNGT)\n",
    "    return CGTNGT_list\n",
    "def constructDistanceList(SPD, total_node_num):\n",
    "    dis_list = []\n",
    "    for i in range(total_node_num):\n",
    "        dis = SPD[i]['dis']\n",
    "        if dis == 'inf':\n",
    "            dis = -1\n",
    "        dis_list.append(dis)\n",
    "    return dis_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyze Data Package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_data(dataset_id=13):\n",
    "    graph_obj = load_data(dataset_id)\n",
    "    dataset_name = graph_obj[\"common\"][\"name\"]\n",
    "    common = graph_obj[\"common\"]\n",
    "    individual = graph_obj[\"individual\"]\n",
    "    SPD = common[\"graph_additional_info\"][\"SPD\"]\n",
    "    total_node_num = len(SPD)\n",
    "    ground_truth = common[\"graph_target\"][\"node_features\"]\n",
    "    GCN_output = individual['GCN'][\"graph_out\"][\"node_features\"]\n",
    "    GCNWF_output = individual['GCN_Identity_features'][\"graph_out\"][\"node_features\"]\n",
    "    MLP_output = individual[\"MLP\"][\"graph_out\"][\"node_features\"]\n",
    "    KFS = common[\"graph_additional_info\"][\"KFS\"]\n",
    "    GCN_name = individual[\"GCN\"][\"real_model_name\"]\n",
    "    GCNWF_name = individual['GCN_Identity_features'][\"real_model_name\"]\n",
    "    MLP_name = individual['MLP'][\"real_model_name\"]\n",
    "    major_label_dict = {}\n",
    "    for i in range(len(SPD)):\n",
    "        label_list = getMajorLabelList(SPD[i])\n",
    "        if len(label_list) == 1:\n",
    "            major_label_dict[i] = label_list[0]\n",
    "\n",
    "    KFS_major_label_dict = {}\n",
    "    for i in range(len(SPD)):\n",
    "        label_list = getMajorLabelList(KFS[i])\n",
    "        if len(label_list) == 1:\n",
    "            KFS_major_label_dict[i] = label_list[0]\n",
    "    #table_header = [\"Dataset\", \"Model\", \"Analysis Type\", \"Error\", \"Error Rate\", \"Correct\", \"Correct Rate\", \"Total\"]\n",
    "    results_list = []\n",
    "    GCN_TOTAL_return_result = error_distribution_analysis(ground_truth, GCN_output)\n",
    "    results_list.append([dataset_name, GCN_name, \"TOTAL\"] + GCN_TOTAL_return_result)\n",
    "    GCNWF_TOTAL_return_result = error_distribution_analysis(ground_truth, GCNWF_output)\n",
    "    results_list.append([dataset_name, GCNWF_name, \"TOTAL\"] + GCNWF_TOTAL_return_result)\n",
    "    MLP_TOTAL_return_result = error_distribution_analysis(ground_truth, MLP_output)\n",
    "    results_list.append([dataset_name, MLP_name, \"TOTAL\"] + MLP_TOTAL_return_result)\n",
    "    \n",
    "    GCN_SPD_return_result = Inconsistency_error_pattern_analysis(ground_truth, major_label_dict, GCN_output)\n",
    "    results_list.append([dataset_name, GCN_name, \"SPD\"] + GCN_SPD_return_result)\n",
    "    GCNWF_SPD_return_result = Inconsistency_error_pattern_analysis(ground_truth, major_label_dict, GCNWF_output)\n",
    "    results_list.append([dataset_name, GCNWF_name, \"SPD\"] + GCNWF_SPD_return_result)\n",
    "    MLP_SPD_return_result = Inconsistency_error_pattern_analysis(ground_truth, major_label_dict, MLP_output)\n",
    "    results_list.append([dataset_name, MLP_name, \"SPD\"] + MLP_SPD_return_result)\n",
    "    \n",
    "    GCN_KFS_return_result = Inconsistency_error_pattern_analysis(ground_truth, KFS_major_label_dict, GCN_output)\n",
    "    results_list.append([dataset_name, GCN_name, \"KFS\"] + GCN_KFS_return_result)\n",
    "    GCNWF_KFS_return_result = Inconsistency_error_pattern_analysis(ground_truth, KFS_major_label_dict, GCNWF_output)\n",
    "    results_list.append([dataset_name, GCNWF_name, \"KFS\"] + GCNWF_KFS_return_result)\n",
    "    MLP_KFS_return_result = Inconsistency_error_pattern_analysis(ground_truth, KFS_major_label_dict, MLP_output)\n",
    "    results_list.append([dataset_name, MLP_name, \"KFS\"] + MLP_KFS_return_result)\n",
    "    \n",
    "    GCN_SK_return_result = Multiple_inconsistency_error_pattern_analysis(ground_truth, major_label_dict, KFS_major_label_dict, GCN_output)\n",
    "    results_list.append([dataset_name, GCN_name, \"SPD+KFS\"] + GCN_SK_return_result)\n",
    "    GCNWF_SK_return_result = Multiple_inconsistency_error_pattern_analysis(ground_truth, major_label_dict, KFS_major_label_dict, GCNWF_output)\n",
    "    results_list.append([dataset_name, GCNWF_name, \"SPD+KFS\"] + GCNWF_SK_return_result)\n",
    "    MLP_SK_return_result = Multiple_inconsistency_error_pattern_analysis(ground_truth, major_label_dict, KFS_major_label_dict, MLP_output)\n",
    "    results_list.append([dataset_name, MLP_name, \"SPD+KFS\"] + MLP_SK_return_result)\n",
    "    return results_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('outputs/results.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    table_header = [\"Dataset\", \"Model\", \"Analysis Type\", \"Error\", \"Error Rate\", \"Correct\", \"Correct Rate\", \"Total\"]\n",
    "    writer.writerow(table_header)\n",
    "    for dataset_id in [4,5,6,7,9,13]:\n",
    "        results_list = analyze_data(dataset_id)\n",
    "        writer.writerows(results_list)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def comprehensive_analyze(dataset_id):\n",
    "    graph_obj = load_data(dataset_id)\n",
    "    dataset_name = graph_obj[\"common\"][\"name\"]\n",
    "    common = graph_obj[\"common\"]\n",
    "    individual = graph_obj[\"individual\"]\n",
    "    SPD = common[\"graph_additional_info\"][\"SPD\"]\n",
    "    total_node_num = len(SPD)\n",
    "    ground_truth = common[\"graph_target\"][\"node_features\"]\n",
    "    GCN_output = individual['GCN'][\"graph_out\"][\"node_features\"]\n",
    "    GCNWF_output = individual['GCN_Identity_features'][\"graph_out\"][\"node_features\"]\n",
    "    MLP_output = individual[\"MLP\"][\"graph_out\"][\"node_features\"]\n",
    "    KFS = common[\"graph_additional_info\"][\"KFS\"]\n",
    "    GCN_name = individual[\"GCN\"][\"real_model_name\"]\n",
    "    GCNWF_name = individual['GCN_Identity_features'][\"real_model_name\"]\n",
    "    MLP_name = individual['MLP'][\"real_model_name\"]\n",
    "    major_label_dict = {}\n",
    "    for i in range(len(SPD)):\n",
    "        label_list = getMajorLabelList(SPD[i])\n",
    "        if len(label_list) == 1:\n",
    "            major_label_dict[i] = label_list[0]\n",
    "\n",
    "    KFS_major_label_dict = {}\n",
    "    for i in range(len(SPD)):\n",
    "        label_list = getMajorLabelList(KFS[i])\n",
    "        if len(label_list) == 1:\n",
    "            KFS_major_label_dict[i] = label_list[0]\n",
    "    graph_in = common[\"graph_in\"]\n",
    "    neighbor_set = constructNeighborSet(graph_in)\n",
    "    degree_list = constructDegreeList(neighbor_set, total_node_num)\n",
    "    CGTNGT_list = constructCGTNGTList(ground_truth, neighbor_set, total_node_num)\n",
    "    Distance_list = constructDistanceList(SPD, total_node_num)\n",
    "    GCN_Comp_return_result = Comprehensive_error_pattern_analysis(ground_truth, major_label_dict, KFS_major_label_dict,CGTNGT_list,0.38,Distance_list, GCN_output)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cora 0.19897747039794922\n",
      "Inconsistency Analysis:\n",
      "Error:25 (0.9615384615384616) Correct:1 (0.038461538461538436) Total:26 \n",
      "[162, 323, 332, 498, 554, 606, 644, 767, 1072, 1288, 1329, 1343, 1394, 1494, 1507, 1594, 1649, 1661, 1920, 1983, 1998, 2014, 2015, 2175, 2355, 2427]\n",
      "citeseer 0.2728714942932129\n",
      "Inconsistency Analysis:\n",
      "Error:23 (1.0) Correct:0 (0.0) Total:23 \n",
      "[155, 367, 487, 653, 825, 1007, 1026, 1096, 1132, 1178, 1338, 1429, 1447, 1819, 1942, 2089, 2119, 2150, 2313, 2529, 2643, 2992, 3197]\n",
      "pubmed 2.162975788116455\n",
      "Inconsistency Analysis:\n",
      "Error:29 (0.9666666666666667) Correct:1 (0.033333333333333326) Total:30 \n",
      "[799, 863, 2337, 4058, 4129, 4509, 5993, 6424, 6460, 6509, 6572, 6948, 7307, 8165, 8335, 8661, 9767, 10175, 11084, 11134, 11762, 12910, 13054, 15057, 15654, 16446, 18125, 18546, 18813, 19211]\n",
      "cora_ml 0.3611903190612793\n",
      "Inconsistency Analysis:\n",
      "Error:33 (0.7674418604651163) Correct:10 (0.2325581395348837) Total:43 \n",
      "[315, 353, 522, 692, 756, 770, 930, 1092, 1112, 1141, 1146, 1422, 1430, 1578, 1621, 1642, 1661, 1664, 1687, 1731, 1754, 1802, 1804, 1805, 1817, 1867, 2064, 2073, 2078, 2110, 2145, 2148, 2291, 2364, 2417, 2446, 2513, 2514, 2553, 2572, 2576, 2618, 2722]\n",
      "Photo 1.8669347763061523\n",
      "Inconsistency Analysis:\n",
      "Error:49 (0.8305084745762712) Correct:10 (0.1694915254237288) Total:59 \n",
      "[213, 283, 450, 648, 752, 904, 986, 1058, 1201, 1377, 1432, 1546, 1575, 1624, 1670, 1693, 1826, 1853, 1862, 1990, 2032, 2215, 2287, 2375, 2537, 2811, 2856, 2958, 3068, 3069, 3187, 3334, 3522, 3817, 3895, 4067, 4315, 4376, 4466, 4743, 4805, 4822, 5132, 5251, 5287, 5446, 5629, 5641, 5962, 6028, 6047, 6138, 6455, 6553, 6794, 7147, 7151, 7252, 7349]\n",
      "cora_ml 0.36400628089904785\n",
      "Inconsistency Analysis:\n",
      "Error:35 (0.813953488372093) Correct:8 (0.18604651162790697) Total:43 \n",
      "[315, 353, 522, 692, 756, 770, 930, 1092, 1112, 1141, 1146, 1422, 1430, 1578, 1621, 1642, 1661, 1664, 1687, 1731, 1754, 1802, 1804, 1805, 1817, 1867, 2064, 2073, 2078, 2110, 2145, 2148, 2291, 2364, 2417, 2446, 2513, 2514, 2553, 2572, 2576, 2618, 2722]\n"
     ]
    }
   ],
   "source": [
    "for dataset_id in [4,5,6,7,9,13]:\n",
    "    comprehensive_analyze(dataset_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Cora-GCN\n",
    "CGTNGT<=0.0 and Distance in [1.2]\n",
    "Error:27 (0.9) Correct:3 (0.09999999999999998) Total:30 \n",
    "CGTNGT<=0.6 and Distance in [1,2]\n",
    "Error:97 (0.8738738738738738) Correct:14 (0.12612612612612617) Total:111 \n",
    "CGTNGT<=0.6 and Remove Distance\n",
    "Error:124 (0.8493150684931506) Correct:22 (0.15068493150684936) Total:146 \n",
    "Distance<=1  \n",
    "Error:45 (0.8490566037735849) Correct:8 (0.15094339622641506) Total:53 \n",
    "CGTNGT<=0.3 and Distance<=1 and SPD inconsistency and KFS inconsistency:\n",
    "Error:19 (0.95) Correct:1 (0.050000000000000044) Total:20 \n",
    "CGTNGT<=0.38 and Distance<=1 and SPD+KFS inconsistency\n",
    "Error:25 (0.9615384615384616) Correct:1 (0.038461538461538436) Total:26 \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
