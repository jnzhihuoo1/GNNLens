{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "dataset = CoraGraphDataset()\n",
    "graph = dataset[0]\n",
    "nlabels = graph.ndata['label']\n",
    "num_classes = dataset.num_classes\n",
    "features = graph.ndata['feat']\n",
    "labels = graph.ndata['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graph(num_nodes=2708, num_edges=10556,\n",
       "      ndata_schemes={'feat': Scheme(shape=(1433,), dtype=torch.float32), 'label': Scheme(shape=(), dtype=torch.int64), 'test_mask': Scheme(shape=(), dtype=torch.bool), 'train_mask': Scheme(shape=(), dtype=torch.bool), 'val_mask': Scheme(shape=(), dtype=torch.bool)}\n",
       "      edata_schemes={})"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnnlens.GNNLensWriter as GNNLensWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating SPD metrics for Cora\n",
      "Finished: 0.0025801658630371094\n",
      "> Calculating KFS metrics for Cora\n",
      "Finished: 0.011400461196899414\n",
      "> Calculating layout for Cora\n",
      "Finished: 0.0013010501861572266\n",
      "Finish calculating metrics for Cora.\n"
     ]
    }
   ],
   "source": [
    "writer = GNNLensWriter(\"subgraph_examples_data\")\n",
    "\n",
    "graph = dataset[0]\n",
    "nlabels = graph.ndata['label']\n",
    "num_classes = dataset.num_classes\n",
    "features = graph.ndata['feat']\n",
    "\n",
    "writer.add_graph(\"Cora\", graph, nlabels, num_classes, features, calculate_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "\n",
    "def get_identity_features(features):\n",
    "    num_node = features.shape[0]\n",
    "    features = torch.eye(num_node)\n",
    "    return features\n",
    "\n",
    "def get_identity_graph(g):\n",
    "    num_nodes = g.num_nodes()\n",
    "    srcs = [i for i in range(num_nodes)]\n",
    "    tgts = [i for i in range(num_nodes)]\n",
    "    new_g = dgl.graph((srcs, tgts))\n",
    "    return new_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN with two layers...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "# Define a class for GCN\n",
    "class GCN(nn.Module):\n",
    "       def __init__(self,\n",
    "                           in_feats,\n",
    "                           num_classes,\n",
    "                           num_layers):\n",
    "           super(GCN, self).__init__()\n",
    "           self.layers = nn.ModuleList()\n",
    "           self.layers.append(GraphConv(in_feats, num_classes))\n",
    "           for _ in range(num_layers - 1):\n",
    "                self.layers.append(GraphConv(num_classes, num_classes))\n",
    "\n",
    "       def forward(self, g, h):\n",
    "             for layer in self.layers:\n",
    "                  h = layer(g, h)\n",
    "             return h\n",
    "\n",
    "# Define a function to train a GCN with the specified number of layers \n",
    "# and return the predictions\n",
    "def train_gcn(g, num_layers, num_classes, identity_features=False, identity_adj=False):\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    if identity_features:\n",
    "        features = get_identity_features(features)\n",
    "    if identity_adj:\n",
    "        g = get_identity_graph(g)\n",
    "    \n",
    "    model = GCN(in_feats=features.shape[1],\n",
    "                             num_classes=num_classes,\n",
    "                             num_layers=num_layers)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "      \n",
    "    num_epochs = 200\n",
    "    model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        logits = model(g, features)\n",
    "        loss = loss_func(logits[train_mask], labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    model.eval()\n",
    "    predictions = model(g, features)\n",
    "    _, predicted_classes = torch.max(predictions, dim=1)\n",
    "    confidence = F.softmax(predictions, dim=1)\n",
    "    return predicted_classes, confidence, model\n",
    "\n",
    "\n",
    "print(\"Training GCN with two layers...\")\n",
    "predicted_classes_GCN, output_vector_GCN, model = train_gcn(graph, num_layers=2, num_classes=num_classes)\n",
    "#print(\"Training MLP with two layers...\")\n",
    "#predicted_classes_MLP, output_vector_MLP = train_gcn(graph, num_layers=2, num_classes=num_classes, identity_adj=True)\n",
    "\n",
    "#print(\"Training GCNWUF with two layers...\")\n",
    "#predicted_classes_GCNWUF, output_vector_GCNWUF = train_gcn(graph, num_layers=2, num_classes=num_classes, identity_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model_key 0 is main model.\n",
    "## model_key 1 is main model without structure.\n",
    "## model_key 2 is main model without features.\n",
    "writer.add_model(\"Cora\", \"GCN\", predicted_classes_GCN, output_vector_GCN)\n",
    "#writer.add_model(\"Cora\", \"MLP\", predicted_classes_MLP, output_vector_MLP, 1)\n",
    "#writer.add_model(\"Cora\", \"GCNWUF\", predicted_classes_GCNWUF, output_vector_GCNWUF, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "from captum.attr import IntegratedGradients\n",
    "from dgl.nn import GraphConv\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required by IntegratedGradients\n",
    "h = graph.ndata['feat'].clone().requires_grad_(True)\n",
    "#model = GCN(h.shape[1], num_classes)\n",
    "def wrap_up_func(model, g):\n",
    "    def forward_replace(h):\n",
    "        return model(g,h)\n",
    "    return forward_replace\n",
    "ig = IntegratedGradients(wrap_up_func(model, graph))\n",
    "# Attribute the predictions for node class 0 to the input features\n",
    "feat_attr = ig.attribute(h, target=predicted_classes_GCN[0], internal_batch_size=graph.num_nodes(), n_steps=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "node_weights = feat_attr.abs().sum(dim=1)\n",
    "node_weights = (node_weights - node_weights.min()) / node_weights.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsecond_subgraph = extract_subgraph(graph, 1)\\nwriter.add_subgraph(graph_name='Cora', subgraph_name='IntegratedGradients', node_id=1,\\n                                  subgraph_nids=second_subgraph.ndata[dgl.NID],\\n                                  subgraph_eids=second_subgraph.edata[dgl.EID],\\n                                  subgraph_nweights=second_subgraph.ndata['weight'],\\n                                  subgraph_eweights=second_subgraph.edata['weight'])\\n                                  \""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import dgl\n",
    "import torch\n",
    "\n",
    "def extract_subgraph(g, node):\n",
    "    seed_nodes = [node]\n",
    "    sg = dgl.in_subgraph(g, seed_nodes)\n",
    "    src, dst = sg.edges()\n",
    "    seed_nodes = torch.cat([src, dst]).unique()\n",
    "    sg = dgl.in_subgraph(g, seed_nodes, relabel_nodes=True)\n",
    "    return sg\n",
    "\n",
    "graph.ndata['weight'] = node_weights\n",
    "graph.edata['weight'] = torch.ones(graph.num_edges(),)\n",
    "first_subgraph = extract_subgraph(graph, 0)\n",
    "writer.add_subgraph(graph_name='Cora', subgraph_name='IntegratedGradients', node_id=0,\n",
    "                                  subgraph_nids=first_subgraph.ndata[dgl.NID],\n",
    "                                  subgraph_eids=first_subgraph.edata[dgl.EID],\n",
    "                                  subgraph_nweights=first_subgraph.ndata['weight'],\n",
    "                                  subgraph_eweights=first_subgraph.edata['weight'])\n",
    "'''\n",
    "second_subgraph = extract_subgraph(graph, 1)\n",
    "writer.add_subgraph(graph_name='Cora', subgraph_name='IntegratedGradients', node_id=1,\n",
    "                                  subgraph_nids=second_subgraph.ndata[dgl.NID],\n",
    "                                  subgraph_eids=second_subgraph.edata[dgl.EID],\n",
    "                                  subgraph_nweights=second_subgraph.ndata['weight'],\n",
    "                                  subgraph_eweights=second_subgraph.edata['weight'])\n",
    "                                  '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnnlens --logdir /data2/zhihua/github/GNNLens/server/gnnlenswriter/examples_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
