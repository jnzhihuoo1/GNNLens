{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using backend: pytorch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n"
     ]
    }
   ],
   "source": [
    "from dgl.data import CoraGraphDataset\n",
    "\n",
    "dataset = CoraGraphDataset()\n",
    "graph = dataset[0]\n",
    "nlabels = graph.ndata['label']\n",
    "num_classes = dataset.num_classes\n",
    "features = graph.ndata['feat']\n",
    "labels = graph.ndata['label']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2708"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.num_nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gnnlens.GNNLensWriter as GNNLensWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Calculating SPD metrics for Cora\n",
      "Finished: 0.003002166748046875\n",
      "> Calculating KFS metrics for Cora\n",
      "Finished: 0.009807586669921875\n",
      "> Calculating layout for Cora\n",
      "Finished: 0.0012743473052978516\n",
      "Finish calculating metrics for Cora.\n"
     ]
    }
   ],
   "source": [
    "writer = GNNLensWriter(\"examples_data\")\n",
    "\n",
    "graph = dataset[0]\n",
    "nlabels = graph.ndata['label']\n",
    "num_classes = dataset.num_classes\n",
    "features = graph.ndata['feat']\n",
    "\n",
    "writer.add_graph(\"Cora\", graph, nlabels, num_classes, features, calculate_metrics=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import dgl\n",
    "\n",
    "def get_identity_features(features):\n",
    "    num_node = features.shape[0]\n",
    "    features = torch.eye(num_node)\n",
    "    return features\n",
    "\n",
    "def get_identity_graph(g):\n",
    "    num_nodes = g.num_nodes()\n",
    "    srcs = [i for i in range(num_nodes)]\n",
    "    tgts = [i for i in range(num_nodes)]\n",
    "    new_g = dgl.graph((srcs, tgts))\n",
    "    return new_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training GCN with two layers...\n",
      "Training MLP with two layers...\n",
      "Training GCNWUF with two layers...\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from dgl.nn.pytorch import GraphConv\n",
    "\n",
    "# Define a class for GCN\n",
    "class GCN(nn.Module):\n",
    "       def __init__(self,\n",
    "                           in_feats,\n",
    "                           num_classes,\n",
    "                           num_layers):\n",
    "           super(GCN, self).__init__()\n",
    "           self.layers = nn.ModuleList()\n",
    "           self.layers.append(GraphConv(in_feats, num_classes))\n",
    "           for _ in range(num_layers - 1):\n",
    "                self.layers.append(GraphConv(num_classes, num_classes))\n",
    "\n",
    "       def forward(self, g, h):\n",
    "             for layer in self.layers:\n",
    "                  h = layer(g, h)\n",
    "             return h\n",
    "\n",
    "# Define a function to train a GCN with the specified number of layers \n",
    "# and return the predictions\n",
    "def train_gcn(g, num_layers, num_classes, identity_features=False, identity_adj=False):\n",
    "    features = g.ndata['feat']\n",
    "    labels = g.ndata['label']\n",
    "    train_mask = g.ndata['train_mask']\n",
    "    if identity_features:\n",
    "        features = get_identity_features(features)\n",
    "    if identity_adj:\n",
    "        g = get_identity_graph(g)\n",
    "    \n",
    "    model = GCN(in_feats=features.shape[1],\n",
    "                             num_classes=num_classes,\n",
    "                             num_layers=num_layers)\n",
    "    loss_func = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "      \n",
    "    num_epochs = 200\n",
    "    model.train()\n",
    "    for _ in range(num_epochs):\n",
    "        logits = model(g, features)\n",
    "        loss = loss_func(logits[train_mask], labels[train_mask])\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "      \n",
    "    model.eval()\n",
    "    predictions = model(g, features)\n",
    "    _, predicted_classes = torch.max(predictions, dim=1)\n",
    "    confidence = F.softmax(predictions, dim=1)\n",
    "    return predicted_classes, confidence\n",
    "\n",
    "\n",
    "print(\"Training GCN with two layers...\")\n",
    "predicted_classes_GCN, output_vector_GCN = train_gcn(graph, num_layers=2, num_classes=num_classes)\n",
    "print(\"Training MLP with two layers...\")\n",
    "predicted_classes_MLP, output_vector_MLP = train_gcn(graph, num_layers=2, num_classes=num_classes, identity_adj=True)\n",
    "\n",
    "print(\"Training GCNWUF with two layers...\")\n",
    "predicted_classes_GCNWUF, output_vector_GCNWUF = train_gcn(graph, num_layers=2, num_classes=num_classes, identity_features=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "## model_key 0 is main model.\n",
    "## model_key 1 is main model without structure.\n",
    "## model_key 2 is main model without features.\n",
    "writer.add_model(\"Cora\", \"GCN\", predicted_classes_GCN, output_vector_GCN, 0)\n",
    "writer.add_model(\"Cora\", \"MLP\", predicted_classes_MLP, output_vector_MLP, 1)\n",
    "writer.add_model(\"Cora\", \"GCNWUF\", predicted_classes_GCNWUF, output_vector_GCNWUF, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gnnlens --logdir /data2/zhihua/github/GNNLens/server/gnnlenswriter/examples_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
