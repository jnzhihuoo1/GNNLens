{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __init__ import *\n",
    "import pickle as pkl\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "VERSION_ID = \"V1_2\"\n",
    "def read_json(file_name):\n",
    "    with open(file_name, \"r\") as f:\n",
    "        obj = json.load(f)\n",
    "    return obj\n",
    "\n",
    "def getDatasetsList(logdir):\n",
    "    filename = Path(logdir) / 'datasetlist_{}.json'.format(VERSION_ID)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"{} is not existed\".format(filename))\n",
    "        return None\n",
    "    else:\n",
    "        datasets_released_list = read_json(filename)\n",
    "        return datasets_released_list\n",
    "\n",
    "def getGraphBundleInfo(logdir, dataset_id):\n",
    "    filename = Path(logdir) / 'cache_bundle_{}_{}.json'.format(dataset_id, VERSION_ID)\n",
    "    if not os.path.isfile(filename):\n",
    "        print(\"{} is not existed\".format(filename))\n",
    "        return None\n",
    "    else:\n",
    "        graph_pkg = read_json(filename)\n",
    "        return graph_pkg    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "graphbundle_obj = getGraphBundleInfo(\"/data2/zhihua/github/GNNLens/gnnlens/public/data/\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['graph_obj', 'success'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphbundle_obj.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['common', 'individual'])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphbundle_obj[\"graph_obj\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphbundle_obj[\"graph_obj\"][\"individual\"][\"GCN\"][\"model\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'graph_out', 'message_passing', 'model', 'real_model_name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys(['node_features', 'output_vector'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_keys(['GCN', 'GCN_Identity_features', 'MLP'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['test', 'train', 'valid'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graphbundle_obj[\"graph_obj\"][\"common\"][\"mask\"].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGraphBundleInfo(dataset_id):\n",
    "    if dataset_id in dataset_keys:\n",
    "        graph_bundle_info = graphs_list[\"graphs\"][dataset_id][\"bundle_info\"]\n",
    "        explain_id = 4\n",
    "        graph_id = 1\n",
    "        return_package = {}\n",
    "        common_flag = False\n",
    "        common_package = {}\n",
    "        individual_package = {}\n",
    "        for key in graph_bundle_info:\n",
    "            model_id = graph_bundle_info[key][\"model_id\"]\n",
    "            real_model_name = graph_bundle_info[key].get(\"real_model_name\", DefaultNameMapping[key])\n",
    "            graph_info = getGraphInfo(dataset_id, model_id, explain_id, graph_id)\n",
    "            return_package[key] = graph_info\n",
    "            if not common_flag:\n",
    "                '''\n",
    "                common_package = {\n",
    "                    \"dataset_id\": graph_info[\"dataset_id\"],\n",
    "                    \"data_type_id\": graph_info[\"data_type_id\"],\n",
    "                    \"graph\": graph_info[\"graph\"],\n",
    "                    \"explain_id\": graph_info[\"explain_id\"],\n",
    "                    \"task\": graph_info[\"task\"],\n",
    "                    \"graph_in\": graph_info[\"graph_in\"],\n",
    "                    \"graph_target\":graph_info[\"graph_target\"],\n",
    "                    \"graph_explaination\":graph_info[\"graph_explaination\"],\n",
    "                    \"graph_layout\":graph_info[\"graph_layout\"], \n",
    "                    \"embedding\":graph_info[\"embedding\"],\n",
    "                    \"mask\":graph_info[\"mask\"],\n",
    "                    \"graph_additional_info\":graph_info[\"graph_additional_info\"],\n",
    "                    \"name\":graph_info[\"name\"]\n",
    "                }'''\n",
    "                common_package = {\n",
    "                    \"dataset_id\": graph_info[\"dataset_id\"],\n",
    "                    \"data_type_id\": graph_info[\"data_type_id\"],\n",
    "                    \"graph\": graph_info[\"graph\"],\n",
    "                    \"explain_id\": graph_info[\"explain_id\"],\n",
    "                    \"task\": graph_info[\"task\"],\n",
    "                    \"graph_in\": graph_info[\"graph_in\"],\n",
    "                    \"graph_target\":graph_info[\"graph_target\"],\n",
    "                    \"graph_explaination\":graph_info[\"graph_explaination\"],\n",
    "                    \"graph_layout\":graph_info[\"graph_layout\"], \n",
    "                    \"mask\":graph_info[\"mask\"],\n",
    "                    \"graph_additional_info\":graph_info[\"graph_additional_info\"],\n",
    "                    \"name\":graph_info[\"name\"]\n",
    "                }\n",
    "                common_flag = True\n",
    "            else:\n",
    "                pass\n",
    "            '''\n",
    "            local_individual_package = {\n",
    "                \"model\": graph_info[\"model\"],\n",
    "                \"graph_out\":graph_info[\"graph_out\"],\n",
    "                \"message_passing\":graph_info[\"message_passing\"],\n",
    "                \"model_state_dict\":graph_info[\"model_state_dict\"],\n",
    "            }\n",
    "            '''\n",
    "            \n",
    "            local_individual_package = {\n",
    "                \"model\": graph_info[\"model\"],\n",
    "                \"graph_out\":graph_info[\"graph_out\"],\n",
    "                \"real_model_name\": real_model_name\n",
    "            }\n",
    "            if key == \"GCN\":\n",
    "                local_individual_package[\"message_passing\"] = graph_info[\"message_passing\"]\n",
    "            \n",
    "            individual_package[key] = local_individual_package\n",
    "        return_package = {\n",
    "            \"common\": common_package,\n",
    "            \"individual\": individual_package\n",
    "        }\n",
    "        #if ENABLE_COMPRESSED:\n",
    "        #    return_package = compress_data(return_package)\n",
    "        if ENABLE_CACHE:\n",
    "            saveCacheGraphBundleInfo(dataset_id, return_package)\n",
    "        return return_package\n",
    "        \n",
    "    else:\n",
    "        print(\"Not found dataset id {}\".format(dataset_id))\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Dump data for GNNVis\"\"\"\n",
    "import dgl.backend as F\n",
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "from dgl import DGLError\n",
    "\n",
    "class GNNLensWriter():\n",
    "    \"\"\"\n",
    "    Parameters\n",
    "    ----------\n",
    "    logdir: str\n",
    "        Path to create a new directory for dumping data files, which can \n",
    "        be either a relative path or an absolute path.\n",
    "    \"\"\"\n",
    "    def __init__(self, logdir, exist_ok=False):\n",
    "        os.makedirs(logdir, exist_ok=exist_ok)\n",
    "        self.logdir = logdir\n",
    "        self.graph_names = []\n",
    "        self.graph_data = dict()\n",
    "        self.VERSION_ID = \"V1_2\"\n",
    "        \n",
    "    def _get_graph_logdir(self, name):\n",
    "        \"\"\"Get logdir for the graph.\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the graph.\n",
    "        \"\"\"\n",
    "        return os.path.join(self.logdir, str(self.graph_data[name]['dataset_id']))\n",
    "    \n",
    "    def add_graph(self, name, graph, nlabels, num_nlabel_types, features, mask, graph_additional_info):\n",
    "        \"\"\"Add data for a graph.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        name : str\n",
    "            Name of the graph.\n",
    "        graph : DGLGraph\n",
    "            A homogeneous graph.\n",
    "        nlabels : Tensor of integers, optional\n",
    "            Node labels. The tensor can be reshaped as (N,) where N is the number of nodes.\n",
    "            Each node should be associated with one label only.\n",
    "        num_nlabel_types : int, optional\n",
    "            Number of node label types. If not provided and nlabels is provided,\n",
    "            this will be inferred then. num_nlabel_types should be no greater than 10.\n",
    "        eweights : dict[str, tensor]\n",
    "            Edge weights. The keys are the eweight names, e.g. confidence. The values are the\n",
    "            tensors of edge weights. The tensors can be reshaped as (E,) where E is the number\n",
    "            of edges.\n",
    "        \"\"\"\n",
    "        if name in self.graph_names:\n",
    "            raise ValueError('Graph name {} has already been used.'.format(name))\n",
    "\n",
    "        num_nodes = graph.num_nodes()\n",
    "        num_edges = graph.num_edges()\n",
    "        \n",
    "        srcs, dsts = graph.edges()\n",
    "        srcs = F.asnumpy(srcs).tolist()\n",
    "        dsts = F.asnumpy(dsts).tolist()\n",
    "\n",
    "        # Handle nlabels\n",
    "        if nlabels is None:\n",
    "            nlabels = []\n",
    "        else:\n",
    "            nlabels = F.asnumpy(nlabels)\n",
    "            try:\n",
    "                nlabels = np.reshape(nlabels, (num_nodes,))\n",
    "            except:\n",
    "                raise DGLError('Node labels should be able to be reshaped as (num_nodes,)')\n",
    "            if num_nlabel_types is None:\n",
    "                num_nlabel_types = int(nlabels.max()) + 1\n",
    "            assert num_nlabel_types <= 10, \\\n",
    "                'Expect num_nlabel_types to be no greater than 10, got {:d}'.format(\n",
    "                    num_nlabel_types)\n",
    "            nlabels = nlabels.tolist()\n",
    "        dataset_id = graph_id\n",
    "        data_type = 2\n",
    "        graph_id = 1\n",
    "        explain_id = 4\n",
    "        task = \"node_classification\"\n",
    "        \n",
    "        ## graph_in\n",
    "        features_sparse, features_sparse_value = constructSparseFeature(features.cpu().numpy())\n",
    "        original_graph = whole_graph[\"graph\"]\n",
    "        original_graph = whole_graph[\"graph\"]\n",
    "        Explain_type = \"MessagePassing\"\n",
    "        graph_layout = []\n",
    "        common_package = {\n",
    "                \"dataset_id\": dataset_id,\n",
    "                \"data_type_id\": data_type,\n",
    "                \"graph\": graph_id,\n",
    "                \"explain_id\": explain_id,\n",
    "                \"task\": task,\n",
    "                \"graph_in\": {\n",
    "                    \"feature\":features_sparse,\n",
    "                    \"feature_value\":features_sparse_value,\n",
    "                    \"senders\":original_graph._indices()[1].tolist(),\n",
    "                    \"receivers\":original_graph._indices()[0].tolist()\n",
    "                },\n",
    "                \"graph_target\":{\n",
    "                    \"node_features\":nlabels,\n",
    "                },\n",
    "                \"graph_explaination\":\n",
    "                {\n",
    "                    \"type\":  Explain_type\n",
    "                },\n",
    "                \"graph_layout\":graph_layout, \n",
    "                \"mask\":mask,\n",
    "                \"graph_additional_info\":graph_additional_info,\n",
    "                \"name\":name\n",
    "        }\n",
    "        '''\n",
    "        local_individual_package = {\n",
    "            \"model\": graph_info[\"model\"],\n",
    "            \"graph_out\":graph_info[\"graph_out\"],\n",
    "            \"real_model_name\": real_model_name\n",
    "        }\n",
    "\n",
    "        individual_package[key] = local_individual_package\n",
    "        '''\n",
    "        individual_package = {}\n",
    "        return_package = {\n",
    "            \"common\": common_package,\n",
    "            \"individual\": individual_package\n",
    "        }\n",
    "        # Register graph name\n",
    "        self.graph_names.append(name)\n",
    "        self.graph_data[name] = return_package\n",
    "\n",
    "    def add_model(self, graph_name, model_name, nlabels, eweights=None):\n",
    "        \"\"\"Add data for a model\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        graph_name : str\n",
    "            Name of the graph.\n",
    "        model_name : str\n",
    "            Nmae of the model.\n",
    "        nlabels : Tensor of integers, optional\n",
    "            Node labels. The tensor can be reshaped as (N,) where N is the number of nodes.\n",
    "            Each node should be associated with one label only.\n",
    "        eweights : dict[str, tensor]\n",
    "            Edge weights. The keys are the eweight names, e.g. confidence. The values are the\n",
    "            tensors of edge weights. The tensors can be reshaped as (E,) where E is the number\n",
    "            of edges. The edge weights should be in range [0, 1].\n",
    "        \"\"\"\n",
    "        assert graph_name in self.graph_names, \\\n",
    "            'Expect add_graph to be called first for graph {}'.format(graph_name)\n",
    "\n",
    "        \n",
    "        # Handle nlabels\n",
    "        nlabels = F.asnumpy(nlabels)\n",
    "        num_nodes = self.graph_data[graph_name]['num_nodes']\n",
    "        try:\n",
    "            nlabels = np.reshape(nlabels, (num_nodes,))\n",
    "        except:\n",
    "            raise DGLError('Node labels should be able to be reshaped as (num_nodes,)')\n",
    "        nlabels = nlabels.tolist()\n",
    "\n",
    "        \n",
    "        # Dump model data file\n",
    "        num_models = len(self.graph_data[graph_name]['model_list']) + 1\n",
    "        model_obj = {\n",
    "            \"name\": model_name,\n",
    "            \"nlabels\": nlabels,\n",
    "            \"eweights\": eweights\n",
    "        }\n",
    "        with open(graph_logdir + '/model_{}.json'.format(num_models), 'w') as f:\n",
    "            json.dump({\"model_obj\": model_obj, \"success\": True}, f)\n",
    "\n",
    "        # Register the model\n",
    "        self.graph_data[graph_name]['model_list'].append(model_name)\n",
    "\n",
    "    def flush(self):\n",
    "        \"\"\"Finish dumping data.\"\"\"\n",
    "        VERSION_ID = self.VERSION_ID\n",
    "        # Dump data list (meta info)\n",
    "        with open(self.logdir + '/datasetlist_{}.json'.format(VERSION_ID), 'w') as f:\n",
    "            datasets = []\n",
    "            for i, name in enumerate(self.graph_names):\n",
    "                datasets.append({\"id\": i + 1, \"name\": name})\n",
    "            json.dump({\"datasets\": datasets, \"success\": True}, f)\n",
    "        \n",
    "        for name in self.graph_names:\n",
    "            graph_id = self.graph_data[name]['id']\n",
    "            VERSION_ID = self.VERSION_ID\n",
    "            # Dump model meta info\n",
    "            with open(self.logdir + '/cache_bundle_{}_{}.json'.format(graph_id, VERSION_ID), 'w') as f:\n",
    "                json.dump({\"success\": True}, f)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
